{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1783,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"Balance_accuracy_2.csv\",low_memory=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "outputs": [
    {
     "data": {
      "text/plain": "      dataset_id  model_id  balance_accuracy\n3820          27       190          0.554348\n2010          12      1480          0.618000\n1882          12       302          0.511000\n1582           9      1802          0.486606\n4485          33       903          0.368534\n...          ...       ...               ...\n3363          22      1758          0.500000\n8924          69       442          0.499022\n3590          24      1510          0.094724\n2077          13       172          0.500000\n2822          17      1392          0.971992\n\n[931 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3820</th>\n      <td>27</td>\n      <td>190</td>\n      <td>0.554348</td>\n    </tr>\n    <tr>\n      <th>2010</th>\n      <td>12</td>\n      <td>1480</td>\n      <td>0.618000</td>\n    </tr>\n    <tr>\n      <th>1882</th>\n      <td>12</td>\n      <td>302</td>\n      <td>0.511000</td>\n    </tr>\n    <tr>\n      <th>1582</th>\n      <td>9</td>\n      <td>1802</td>\n      <td>0.486606</td>\n    </tr>\n    <tr>\n      <th>4485</th>\n      <td>33</td>\n      <td>903</td>\n      <td>0.368534</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3363</th>\n      <td>22</td>\n      <td>1758</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>8924</th>\n      <td>69</td>\n      <td>442</td>\n      <td>0.499022</td>\n    </tr>\n    <tr>\n      <th>3590</th>\n      <td>24</td>\n      <td>1510</td>\n      <td>0.094724</td>\n    </tr>\n    <tr>\n      <th>2077</th>\n      <td>13</td>\n      <td>172</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>2822</th>\n      <td>17</td>\n      <td>1392</td>\n      <td>0.971992</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(ratings,test_size=0.2)\n",
    "# test_data\n",
    "\n",
    "data_model_temp = test_data.loc[test_data['balance_accuracy'] == 0]\n",
    "\n",
    "train_data.add(data_model_temp)\n",
    "test_data = test_data.drop(test_data[test_data['balance_accuracy'] == 0].index)\n",
    "test_data.loc[test_data['balance_accuracy'] == 0]\n",
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1786,
   "outputs": [],
   "source": [
    "datasets = ratings.dataset_id.unique()\n",
    "models = ratings.model_id.unique()\n",
    "\n",
    "data_model_train = pd.DataFrame(index=datasets,columns=models)\n",
    "\n",
    "data_model_test = pd.DataFrame(index=datasets,columns=models)\n",
    "\n",
    "\n",
    "# print(data_model_train)\n",
    "# print(data_model_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1787,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        72        73        74        75        76        77        78    \\\n",
      "0   0.000000  0.958896  0.958319  0.999720  0.999439  0.997482  0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "67  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "68  0.350863  0.358772  0.339103  0.376309  0.333301  0.367780  0.325719   \n",
      "69  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "70  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "71  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "        79        80        81    ...  1612  1613  1614  1615  1616  1617  \\\n",
      "0   0.000000  0.998881  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4   0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "..       ...       ...       ...  ...   ...   ...   ...   ...   ...   ...   \n",
      "67  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "68  0.280354  0.346980  0.308344  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "69  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "70  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "71  0.000000  0.000000  0.000000  ...   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "    1618  1619  1620  1621  \n",
      "0    0.0   0.0   0.0   0.0  \n",
      "1    0.0   0.0   0.0   0.0  \n",
      "2    0.0   0.0   0.0   0.0  \n",
      "3    0.0   0.0   0.0   0.0  \n",
      "4    0.0   0.0   0.0   0.0  \n",
      "..   ...   ...   ...   ...  \n",
      "67   0.0   0.0   0.0   0.0  \n",
      "68   0.0   0.0   0.0   0.0  \n",
      "69   0.0   0.0   0.0   0.0  \n",
      "70   0.0   0.0   0.0   0.0  \n",
      "71   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[72 rows x 1800 columns]\n"
     ]
    }
   ],
   "source": [
    "for row in train_data.itertuples():\n",
    "    # dataset_id = getattr(row,'dataset_id')\n",
    "    # model_id = getattr(row,'model_id')\n",
    "    # balance_accuracy = getattr(row,'balance_accuracy')\n",
    "    data_model_train[row[2]][row[1]] = row[3]\n",
    "data_model_train = data_model_train.fillna(0)\n",
    "print(data_model_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1788,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[0.9404585 0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "for row in test_data.itertuples():\n",
    "    # dataset_id = getattr(row,'dataset_id')\n",
    "    # model_id = getattr(row,'model_id')\n",
    "    # balance_accuracy = getattr(row,'balance_accuracy')\n",
    "    data_model_test[row[2]][row[1]] = row[3]\n",
    "data_model_test = data_model_test.fillna(0)\n",
    "data_model_test = np.array(data_model_test)\n",
    "print(type(data_model_test))\n",
    "print(data_model_test)\n",
    "\n",
    "# test_data_matrix = np.zeros((len(datasets),len(models)))\n",
    "# for line in test_data.itertuples():\n",
    "#     test_data_matrix[line[1] - 1, line[2] - 1] = line[3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1789,
   "outputs": [],
   "source": [
    "# data_model_train.to_csv(\"data_model.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Datasets_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1790,
   "outputs": [],
   "source": [
    "# Datasets_similarity_matrix = pd.DataFrame(index=datasets,columns=datasets)\n",
    "# print(Datasets_similarity_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1791,
   "outputs": [],
   "source": [
    "# import linecache\n",
    "# for i in range(1,len(datasets)+1):\n",
    "#     dataset1_feature = linecache.getline(\"data_node.txt\",i).split(\"\\t\")[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")\n",
    "#     # dataset1_feature = np.array(dataset1_feature)\n",
    "#     for j in range(1,len(datasets)+1):\n",
    "#         dataset2_feature = linecache.getline(\"data_node.txt\",j).split(\"\\t\")[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")\n",
    "#         #dataset2_feature = np.array(dataset2_feature)\n",
    "#         if i == j:\n",
    "#             Datasets_similarity_matrix[j-1][i-1] = 1\n",
    "#         else:\n",
    "#             Datasets_similarity_matrix[j-1][i-1] = cosine_similarity([dataset1_feature,dataset2_feature])[0][1]\n",
    "# Datasets_similarity_matrix.to_csv(\"data_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model_similarity_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1792,
   "outputs": [],
   "source": [
    "# Model_similarity_matrix = pd.DataFrame(index=range(len(models)),columns=range(len(models)))\n",
    "# print(Model_similarity_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1793,
   "outputs": [],
   "source": [
    "# import linecache\n",
    "# for i in range(1,len(datasets)+1):\n",
    "#     model1_feature = linecache.getline(\"model_node.txt\",i).split(\"\\t\")[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")[2:]\n",
    "#     # dataset1_feature = np.array(dataset1_feature)\n",
    "#     for j in range(1,len(datasets)+1):\n",
    "#         model2_feature = linecache.getline(\"model_node.txt\",j).split(\"\\t\")[2].replace(\"[\", \"\").replace(\"]\", \"\").replace(\"\\n\",\"\").replace(\" \",\"\").split(\",\")[2:]\n",
    "#         #dataset2_feature = np.array(dataset2_feature)\n",
    "#         if i == j:\n",
    "#             Model_similarity_matrix[j-1][i-1] = 1\n",
    "#         else:\n",
    "#             Model_similarity_matrix[j-1][i-1] = cosine_similarity([model1_feature,model2_feature])[0][1]\n",
    "# Model_similarity_matrix.to_csv(\"model_model.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1794,
   "outputs": [],
   "source": [
    "# print(data_model.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1795,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 72)\n",
      "(1800, 1800)\n"
     ]
    }
   ],
   "source": [
    "dataset_similarity = cosine_similarity(data_model_train)\n",
    "model_similarity = cosine_similarity(data_model_train.T)\n",
    "\n",
    "dataset_similarity_csv = pd.DataFrame(dataset_similarity,index=datasets,columns=datasets)\n",
    "\n",
    "print(dataset_similarity.shape)\n",
    "print(model_similarity.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1    2        3    4    5         6        7         8   \\\n",
      "0   1.000000  0.000000  0.0  0.00000  0.0  0.0  0.000000  0.00000  0.000000   \n",
      "1   0.000000  1.000000  0.0  0.00000  0.0  0.0  0.000000  0.90471  0.000000   \n",
      "2   0.000000  0.000000  1.0  0.00000  0.0  0.0  0.000000  0.00000  0.622604   \n",
      "3   0.000000  0.000000  0.0  1.00000  0.0  0.0  0.000000  0.00000  0.000000   \n",
      "4   0.000000  0.000000  0.0  0.00000  1.0  0.0  0.000000  0.00000  0.000000   \n",
      "..       ...       ...  ...      ...  ...  ...       ...      ...       ...   \n",
      "67  0.000000  0.000000  0.0  0.00000  0.0  0.0  0.905006  0.00000  0.000000   \n",
      "68  0.802309  0.000000  0.0  0.00000  0.0  0.0  0.000000  0.00000  0.000000   \n",
      "69  0.000000  0.853151  0.0  0.00000  0.0  0.0  0.000000  0.86374  0.000000   \n",
      "70  0.000000  0.000000  0.0  0.00000  0.0  0.0  0.000000  0.00000  0.000000   \n",
      "71  0.000000  0.000000  0.0  0.71506  0.0  0.0  0.000000  0.00000  0.000000   \n",
      "\n",
      "          9   ...        62   63   64   65   66   67        68        69   70  \\\n",
      "0   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.802309  0.000000  0.0   \n",
      "1   0.871090  ...  0.892658  0.0  0.0  0.0  0.0  0.0  0.000000  0.853151  0.0   \n",
      "2   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "3   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "4   0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "..       ...  ...       ...  ...  ...  ...  ...  ...       ...       ...  ...   \n",
      "67  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  1.0  0.000000  0.000000  0.0   \n",
      "68  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  1.000000  0.000000  0.0   \n",
      "69  0.881414  ...  0.852670  0.0  0.0  0.0  0.0  0.0  0.000000  1.000000  0.0   \n",
      "70  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  1.0   \n",
      "71  0.000000  ...  0.000000  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0   \n",
      "\n",
      "         71  \n",
      "0   0.00000  \n",
      "1   0.00000  \n",
      "2   0.00000  \n",
      "3   0.71506  \n",
      "4   0.00000  \n",
      "..      ...  \n",
      "67  0.00000  \n",
      "68  0.00000  \n",
      "69  0.00000  \n",
      "70  0.00000  \n",
      "71  1.00000  \n",
      "\n",
      "[72 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset_similarity_csv)\n",
    "dataset_similarity_csv.to_csv(\"dataset_similarity_csv\",sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1797,
   "outputs": [],
   "source": [
    "def predict(ratings1, similarity):\n",
    "        mean_user_rating = ratings1.mean(axis=1)\n",
    "        ratings_diff = (ratings1 - np.array(mean_user_rating)[:,np.newaxis])\n",
    "        pred = np.array(mean_user_rating)[:,np.newaxis] + np.dot(similarity,ratings_diff) / np.array([np.abs(similarity).sum(axis = 1)]).T\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1798,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        72        73        74        75        76        77        78    \\\n",
      "0   0.119379  0.536762  0.515269  0.712684  0.680991  0.646880  0.342999   \n",
      "1   0.004725  0.004725  0.004725  0.004725  0.004725  0.004725  0.004725   \n",
      "2  -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885   \n",
      "3  -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501   \n",
      "4  -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484   \n",
      "..       ...       ...       ...       ...       ...       ...       ...   \n",
      "67  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749   \n",
      "68  0.133121  0.488279  0.465811  0.669896  0.634873  0.599598  0.364033   \n",
      "69 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916   \n",
      "70 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122   \n",
      "71 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827   \n",
      "\n",
      "        79        80        81    ...      1612      1613      1614      1615  \\\n",
      "0   0.359339  0.709832  0.385896  ...  0.001806  0.001806  0.001806  0.001806   \n",
      "1   0.004725  0.004725  0.004725  ...  0.004725  0.004725  0.004725  0.004725   \n",
      "2  -0.001885 -0.001885 -0.001885  ... -0.001885 -0.001885 -0.001885 -0.001885   \n",
      "3  -0.002501 -0.002501 -0.002501  ... -0.002501 -0.002501 -0.002501 -0.002501   \n",
      "4  -0.003484 -0.003484 -0.003484  ... -0.003484 -0.003484 -0.003484 -0.003484   \n",
      "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
      "67  0.001749  0.001749  0.001749  ...  0.001749  0.001749  0.001749  0.001749   \n",
      "68  0.380045  0.665515  0.409165  ... -0.003134 -0.003134 -0.003134 -0.003134   \n",
      "69 -0.003916 -0.003916 -0.003916  ... -0.003916 -0.003916 -0.003916 -0.003916   \n",
      "70 -0.000122 -0.000122 -0.000122  ... -0.000122 -0.000122 -0.000122 -0.000122   \n",
      "71 -0.003827 -0.003827 -0.003827  ... -0.003827 -0.003827 -0.003827 -0.003827   \n",
      "\n",
      "        1616      1617      1618      1619      1620      1621  \n",
      "0   0.001806  0.001806  0.001806  0.001806  0.001806  0.001806  \n",
      "1   0.004725  0.004725  0.004725  0.004725  0.004725  0.004725  \n",
      "2  -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885  \n",
      "3  -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501  \n",
      "4  -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484  \n",
      "..       ...       ...       ...       ...       ...       ...  \n",
      "67  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749  \n",
      "68 -0.003134 -0.003134 -0.003134 -0.003134 -0.003134 -0.003134  \n",
      "69 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916  \n",
      "70 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122  \n",
      "71 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827  \n",
      "\n",
      "[72 rows x 1800 columns]\n"
     ]
    }
   ],
   "source": [
    "user_prediction = predict(data_model_train,dataset_similarity_csv)\n",
    "\n",
    "model_prediction_csv = pd.DataFrame(user_prediction,index=datasets,columns=models)\n",
    "print(model_prediction_csv)\n",
    "# print(user_prediction_csv)\n",
    "model_prediction_csv.to_csv('model_prediction_csv',sep=\"\\t\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1799,
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1800,
   "outputs": [
    {
     "data": {
      "text/plain": "   0    1    2    3    4    5    6    7    8    9    ...  921  922  923  924  \\\n0    0    0    0    0    0    0    0    0    0    0  ...   71   71   71   71   \n1    0    6    7    9   11   20   25   58   62   77  ...  486  496  498  503   \n\n   925  926  927  928  929  930  \n0   71   71   71   71   71   71  \n1  507  518  554  557  566  578  \n\n[2 rows x 931 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>921</th>\n      <th>922</th>\n      <th>923</th>\n      <th>924</th>\n      <th>925</th>\n      <th>926</th>\n      <th>927</th>\n      <th>928</th>\n      <th>929</th>\n      <th>930</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>6</td>\n      <td>7</td>\n      <td>9</td>\n      <td>11</td>\n      <td>20</td>\n      <td>25</td>\n      <td>58</td>\n      <td>62</td>\n      <td>77</td>\n      <td>...</td>\n      <td>486</td>\n      <td>496</td>\n      <td>498</td>\n      <td>503</td>\n      <td>507</td>\n      <td>518</td>\n      <td>554</td>\n      <td>557</td>\n      <td>566</td>\n      <td>578</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 931 columns</p>\n</div>"
     },
     "execution_count": 1800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_test_numpy = pd.DataFrame(data_model_test.nonzero())\n",
    "data_model_test_numpy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 1801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_model_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1802,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.11937862, 0.34299897, 0.35933913, 0.38589633, 0.26700101,\n       0.36437123, 0.2574341 , 0.11751323, 0.13143173, 0.28380007,\n       0.25485051, 0.55167522, 0.69641271, 0.47128594, 0.40455811,\n       0.39127354, 0.59740861, 0.58272791, 0.45154303, 0.34640723,\n       0.44428843, 0.41765868, 0.40965978, 0.51096367, 0.40604503,\n       0.49225318, 0.41781937, 0.4047554 , 0.10493869, 0.27271924,\n       0.25061628, 0.27118466, 0.09123028, 0.11452734, 0.11337705,\n       0.04874832, 0.09563996, 0.33183395, 0.30565545, 0.13686404,\n       0.11559157, 0.11517041, 0.27271949, 0.25351814, 0.16936473,\n       0.26638141, 0.11402246, 0.16515031, 0.13607413, 0.17072156,\n       0.13974695, 0.1059575 , 0.16623533, 0.10319257, 0.25284366,\n       0.14377644, 0.26270632, 0.31358433, 0.31337163, 0.27044334,\n       0.12521603, 0.12114306, 0.12041079, 0.1216626 , 0.13356998,\n       0.35933396, 0.38765858, 0.41496532, 0.44682382, 0.3495255 ,\n       0.40469045, 0.40765043, 0.47136718, 0.46923861, 0.42016559,\n       0.41060412, 0.35888769, 0.41304981, 0.4039813 , 0.42214102,\n       0.50394618, 0.39718855, 0.17772151, 0.16004291, 0.17568638,\n       0.1836491 , 0.1454623 , 0.18637566, 0.11957777, 0.42658654,\n       0.17596801, 0.11394269, 0.19389619, 0.40483596, 0.33549918,\n       0.33091361, 0.40128504, 0.39222786, 0.40483596, 0.40483596,\n       0.43770635, 0.37757696, 0.47605051, 0.39083844, 0.36572239,\n       0.31737932, 0.40483596, 0.46559158, 0.61851095, 0.60418091,\n       0.30211312, 0.3985659 , 0.39836875, 0.38003857, 0.34470006,\n       0.51709292, 0.67390446, 0.36740962, 0.38953582, 0.2731638 ,\n       0.47540448, 0.45328479, 0.45504274, 0.48750806, 0.46557406,\n       0.45021871, 0.40547828, 0.44925391, 0.45133033, 0.43791459,\n       0.39701827, 0.45831984, 0.31574135, 0.12030968, 0.26432035,\n       0.27859617, 0.24203196, 0.42200714, 0.40307827, 0.07601241,\n       0.06252294, 0.12718598, 0.12373099, 0.11548555, 0.15044451,\n       0.30706972, 0.1059829 , 0.67576914, 0.34098566, 0.4388711 ,\n       0.21902992, 0.5282298 , 0.41155428, 0.70565152, 0.39080926,\n       0.38917091, 0.4043886 , 0.44764023, 0.47144479, 0.38781374,\n       0.43051355, 0.40023017, 0.38630544, 0.70945089, 0.37098144,\n       0.39532641, 0.38675824, 0.39467645, 0.43444092, 0.17192002,\n       0.31727823, 0.32744434, 0.16794183, 0.25175564, 0.56345861,\n       0.36750769, 0.47950769, 0.31258292, 0.35405905, 0.31435188,\n       0.17096525, 0.55691862, 0.55736086, 0.26806064, 0.31250537,\n       0.40005271, 0.40018949, 0.37116122, 0.32818261, 0.39902249,\n       0.32295711, 0.39704002, 0.39911004, 0.34123921, 0.41588474,\n       0.39816182, 0.32425801, 0.3579945 , 0.23908839, 0.39889617,\n       0.62691691, 0.38074693, 0.3538432 , 0.34622005, 0.22184138,\n       0.39205069, 0.47365872, 0.41064933, 0.40328085, 0.42498309,\n       0.69070625, 0.46065035, 0.36775589, 0.65848635, 0.39794617,\n       0.44868807, 0.4161174 , 0.68233588, 0.45224357, 0.43471834,\n       0.40229678, 0.38906813, 0.40479229, 0.43016022, 0.32000922,\n       0.36447756, 0.47562563, 0.36344141, 0.41756259, 0.25878278,\n       0.49843184, 0.44537977, 0.40430119, 0.34661114, 0.21657906,\n       0.4041164 , 0.34973726, 0.38295627, 0.44405972, 0.46929318,\n       0.54289131, 0.36864608, 0.39361793, 0.36447255, 0.34383162,\n       0.35959917, 0.39905306, 0.43362271, 0.43950437, 0.41091041,\n       0.57537912, 0.39741794, 0.39107594, 0.44629437, 0.45288329,\n       0.35845712, 0.45523085, 0.32528817, 0.39680362, 0.41929969,\n       0.39982787, 0.32952551, 0.46503318, 0.41295972, 0.39329348,\n       0.36800018, 0.25726352, 0.3251828 , 0.2442064 , 0.491168  ,\n       0.24238701, 0.39900714, 0.23791985, 0.36356471, 0.54841053,\n       0.15741684, 0.23839113, 0.23420345, 0.24125323, 0.27294473,\n       0.30770443, 0.43508123, 0.48513306, 0.28327281, 0.09784379,\n       0.45479276, 0.46927778, 0.5560276 , 0.55654788, 0.27194262,\n       0.3157054 , 0.53085131, 0.45960516, 0.36455653, 0.39670049,\n       0.40261564, 0.37366961, 0.30385151, 0.47246119, 0.38061506,\n       0.44280501, 0.44019227, 0.43394011, 0.34806732, 0.35905369,\n       0.34224496, 0.15573407, 0.31321071, 0.34016388, 0.32439713,\n       0.34077453, 0.30788366, 0.31732789, 0.28664099, 0.43657406,\n       0.32033052, 0.34630835, 0.38660322, 0.36431723, 0.62853005,\n       0.24851356, 0.25533485, 0.23832018, 0.26550156, 0.11077353,\n       0.55431023, 0.5351346 , 0.51689312, 0.41592446, 0.33414861,\n       0.35611126, 0.32170028, 0.38411193, 0.30984373, 0.40209044,\n       0.3104411 , 0.35383754, 0.40390473, 0.38819943, 0.39473327,\n       0.40192434, 0.24111877, 0.40192434, 0.56148531, 0.47833112,\n       0.30734352, 0.49144311, 0.34826368, 0.37063495, 0.3831857 ,\n       0.32043271, 0.04743982, 0.16632279, 0.17882663, 0.05298606,\n       0.01315774, 0.03716588, 0.10590666, 0.14166231, 0.07840358,\n       0.48182832, 0.28273313, 0.3017215 , 0.29644143, 0.27272719,\n       0.23328356, 0.28001651, 0.24811975, 0.23342501, 0.19746528,\n       0.17306475, 0.16914217, 0.53602189, 0.40027834, 0.31202898,\n       0.17212333, 0.31571586, 0.3178053 , 0.42116873, 0.35778135,\n       0.323614  , 0.49665546, 0.39722789, 0.47440412, 0.32787454,\n       0.39570468, 0.35261643, 0.3235081 , 0.41231493, 0.37213812,\n       0.46040567, 0.45790224, 0.24260265, 0.42650314, 0.32036136,\n       0.12141234, 0.09152828, 0.10746378, 0.18432637, 0.04885335,\n       0.07616744, 0.09012179, 0.31056581, 0.27270893, 0.30215404,\n       0.26954935, 0.28451344, 0.35109576, 0.10647816, 0.12866105,\n       0.11945723, 0.20372738, 0.2339252 , 0.18248252, 0.12273249,\n       0.20446911, 0.20410639, 0.39516983, 0.18103673, 0.11898161,\n       0.21856296, 0.31650322, 0.20689929, 0.10611536, 0.2222412 ,\n       0.17332285, 0.15604346, 0.18204146, 0.17955413, 0.20614015,\n       0.18030562, 0.18279105, 0.16780026, 0.13602644, 0.12435142,\n       0.15539148, 0.13142551, 0.12385873, 0.11934117, 0.12385873,\n       0.12892207, 0.19743733, 0.16840506, 0.12701525, 0.17362548,\n       0.18582305, 0.13188503, 0.16544372, 0.12577289, 0.12068983,\n       0.20626961, 0.10333861, 0.11811955, 0.10369119, 0.10540848,\n       0.09987613, 0.40740786, 0.50593425, 0.48170539, 0.41698233,\n       0.47352197, 0.39902628, 0.25662306, 0.37222255, 0.49432227,\n       0.3993317 , 0.48423745, 0.32416805, 0.32733286, 0.45007512,\n       0.19170235, 0.16901357, 0.17892278, 0.05902481, 0.1926533 ,\n       0.17677698, 0.16766572, 0.18381163, 0.18144568, 0.19559571,\n       0.09931802, 0.26986847, 0.19934802, 0.17835439, 0.16702459,\n       0.16718872, 0.2113402 , 0.15695252, 0.12002262, 0.23367943,\n       0.17835439, 0.5259935 , 0.7139982 , 0.38600632, 0.40611583,\n       0.33380749, 0.33301901, 0.38804887, 0.38623658, 0.44824173,\n       0.43450217, 0.26511517, 0.35287798, 0.38215359, 0.45488254,\n       0.35868273, 0.40074832, 0.43055423, 0.41933217, 0.39522417,\n       0.41939983, 0.44925052, 0.38837379, 0.38712733, 0.48978936,\n       0.39899032, 0.45373366, 0.38621772, 0.03336033, 0.04092611,\n       0.01254321, 0.05847225, 0.0431774 , 0.03228161, 0.066824  ,\n       0.11280358, 0.18283535, 0.20946856, 0.18987827, 0.14902638,\n       0.26623504, 0.22705823, 0.14959684, 0.26623504, 0.33458513,\n       0.3456865 , 0.34574415, 0.16646593, 0.18762859, 0.1660133 ,\n       0.10999145, 0.12452344, 0.17839684, 0.15333752, 0.11024838,\n       0.15591523, 0.04436762, 0.15435169, 0.32258829, 0.16140502,\n       0.31865664, 0.1573374 , 0.30934373, 0.30602649, 0.31981414,\n       0.20656663, 0.10332053, 0.13879937, 0.19667053, 0.10729074,\n       0.16183926, 0.30303965, 0.32817884, 0.32172361, 0.33085871,\n       0.13314086, 0.11978345, 0.14656008, 0.53976746, 0.58784159,\n       0.27296438, 0.53820047, 0.56744195, 0.40072263, 0.30868327,\n       0.30777107, 0.15798249, 0.30814421, 0.31009202, 0.12609093,\n       0.19557147, 0.15402265, 0.1175828 , 0.16519472, 0.16689629,\n       0.10610684, 0.11557184, 0.14123214, 0.14260199, 0.51011168,\n       0.29719733, 0.29511181, 0.31294177, 0.24427452, 0.46688228,\n       0.50998988, 0.54613642, 0.30328696, 0.38818072, 0.37794094,\n       0.12040692, 0.1977449 , 0.13129114, 0.1289384 , 0.1045076 ,\n       0.12483346, 0.22151218, 0.28266176, 0.2658906 , 0.21646558,\n       0.26456016, 0.28999539, 0.1055198 , 0.12647156, 0.18549391,\n       0.11189549, 0.10935067, 0.43151481, 0.3223744 , 0.4002484 ,\n       0.46234537, 0.46151322, 0.35662388, 0.45241056, 0.42032809,\n       0.24757225, 0.12232202, 0.38536025, 0.39569922, 0.23817289,\n       0.14645581, 0.12086806, 0.22608542, 0.22113426, 0.27025763,\n       0.25570864, 0.23866621, 0.23596587, 0.14278675, 0.12206661,\n       0.16645152, 0.07457698, 0.09775269, 0.14272967, 0.16756385,\n       0.17852431, 0.07023811, 0.04431722, 0.64726586, 0.6037254 ,\n       0.44436426, 0.40151631, 0.38832715, 0.30155842, 0.37062861,\n       0.34725404, 0.44332656, 0.70601169, 0.59144315, 0.69727235,\n       0.49805175, 0.36169058, 0.34090009, 0.33880946, 0.48080657,\n       0.48404372, 0.47154624, 0.47961297, 0.38857127, 0.43727349,\n       0.40208409, 0.37503899, 0.42983624, 0.48932314, 0.16332149,\n       0.23468859, 0.21688101, 0.24233868, 0.43019307, 0.10162907,\n       0.17780029, 0.10728172, 0.23322537, 0.12618247, 0.22260855,\n       0.21888102, 0.29870794, 0.11877331, 0.28559446, 0.04014581,\n       0.13569614, 0.23322537, 0.20396553, 0.17355808, 0.17995014,\n       0.06188236, 0.18072404, 0.17868699, 0.23442188, 0.2333247 ,\n       0.20366195, 0.11761724, 0.15072749, 0.16750495, 0.21889344,\n       0.13617631, 0.13772344, 0.15229286, 0.17449544, 0.2174114 ,\n       0.11995108, 0.12271388, 0.10556448, 0.21631463, 0.17197529,\n       0.13498821, 0.12984376, 0.1938573 , 0.26240499, 0.67692925,\n       0.60389409, 0.62344935, 0.46650803, 0.37317756, 0.39343625,\n       0.3445468 , 0.49711538, 0.69534899, 0.42962182, 0.42871267,\n       0.45755601, 0.24440947, 0.45785441, 0.41658043, 0.38780508,\n       0.36331999, 0.40060906, 0.46711636, 0.30537537, 0.39461039,\n       0.46516007, 0.44905562, 0.14412794, 0.02787941, 0.01211726,\n       0.16835384, 0.03472902, 0.13971392, 0.16124168, 0.04949729,\n       0.15215541, 0.05421957, 0.09446627, 0.2861581 , 0.27080468,\n       0.54920428, 0.57240066, 0.56829743, 0.55755144, 0.30862955,\n       0.32329314, 0.30862955, 0.30862955, 0.15625551, 0.30862955,\n       0.30862955, 0.39979167, 0.10608588, 0.18909855, 0.14010935,\n       0.12469566, 0.19251232, 0.16369446, 0.2727982 , 0.27070274,\n       0.11732249, 0.2728254 , 0.32496796, 0.6134854 , 0.36868256,\n       0.31959602, 0.48564815, 0.61507484, 0.17885368, 0.60221451,\n       0.57914415, 0.57936206, 0.2961947 , 0.33333607, 0.27188095,\n       0.31322021, 0.31176614, 0.34406983, 0.31322021, 0.32923796,\n       0.33002432, 0.6908866 , 0.55444535, 0.4637326 , 0.63429581,\n       0.43427428, 0.45831621, 0.40027365, 0.30091149, 0.44326131,\n       0.39633763, 0.44791989, 0.44115776, 0.51507234, 0.48790281,\n       0.36386279, 0.62830481, 0.35512558, 0.41775653, 0.33827976,\n       0.43653975, 0.56900321, 0.46376654, 0.39358531, 0.44326131,\n       0.43800774, 0.35546744, 0.45012579, 0.42155406, 0.06437859,\n       0.09579401, 0.06643715, 0.04802478, 0.13572711, 0.07729989,\n       0.05194095, 0.02706233, 0.22586147, 0.12277644, 0.21343533,\n       0.33378278, 0.04153885, 0.19349107, 0.14858196, 0.41154271,\n       0.15277319, 0.32458779, 0.33771493, 0.35062468, 0.317204  ,\n       0.31655959, 0.31020088, 0.15207089, 0.16657344, 0.12493937,\n       0.096168  , 0.16762427, 0.10848923, 0.12346282, 0.17689565,\n       0.15355819, 0.1563747 , 0.04417976, 0.15853572, 0.28226177,\n       0.46276077, 0.32993341, 0.41474442, 0.34245552, 0.41596565,\n       0.40277227, 0.46464005, 0.3197641 , 0.3140117 , 0.41163046,\n       0.45214917, 0.36842816, 0.32977664, 0.24707879, 0.40781126,\n       0.2309596 , 0.19493461, 0.14459343, 0.36629426, 0.13360406,\n       0.22136997, 0.29069576, 0.35323845, 0.60930516, 0.6332602 ,\n       0.4331449 , 0.41476636, 0.38470222, 0.30161535, 0.33893348,\n       0.50281792, 0.61452592, 0.4888597 , 0.38090099, 0.43653702,\n       0.35477967, 0.39057246, 0.36509861, 0.24411392, 0.44512727,\n       0.50913896, 0.36235062, 0.43867121, 0.39363499, 0.38566102,\n       0.38592214, 0.50045619, 0.30470034, 0.43987287, 0.06025977,\n       0.23654333, 0.17385257, 0.20078634, 0.17909066, 0.1532492 ,\n       0.11786605, 0.10253454, 0.17909066, 0.15250104, 0.10297016,\n       0.19198591, 0.12503164, 0.12061474, 0.20947556, 0.12333607,\n       0.10049221, 0.17924791, 0.31265695, 0.35566535, 0.32565006,\n       0.13779537])"
     },
     "execution_count": 1802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model_prediction_csv.to_numpy()[data_model_test.nonzero()].flatten()\n",
    "prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1803,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.9404585 , 0.99943931, 0.99971965, 0.99943931, 0.56042905,\n       0.99860622, 0.32244437, 0.06464099, 0.31613601, 0.29399533,\n       0.33168647, 0.74803712, 0.99678801, 0.99286224, 0.49964311,\n       0.46109922, 0.99643112, 0.76302641, 0.51855817, 0.5       ,\n       0.43897216, 0.51713062, 0.49357602, 0.51498929, 0.50571021,\n       0.51249108, 0.52391149, 0.5       , 0.12386725, 0.2326567 ,\n       0.22318345, 0.20450506, 0.20473748, 0.15675133, 0.17648325,\n       0.2       , 0.16822897, 0.60877855, 0.32918119, 0.2790839 ,\n       0.18982277, 0.18923925, 0.23414126, 0.20590636, 0.2537854 ,\n       0.19612049, 0.2701258 , 0.45144653, 0.2371201 , 0.42242298,\n       0.42058194, 0.14016202, 0.12773765, 0.14379378, 0.14623838,\n       0.13931889, 0.14579506, 0.14067367, 0.1409022 , 0.16843229,\n       0.1410653 , 0.14285714, 0.14285714, 0.14377321, 0.14421772,\n       0.53083522, 0.5       , 0.5       , 0.49880952, 0.74391237,\n       0.43672863, 0.49714647, 0.5       , 0.49519642, 0.52647984,\n       0.59350035, 0.58166792, 0.47949456, 0.46488488, 0.4951571 ,\n       0.39929468, 0.48762031, 0.25993441, 0.21646737, 0.25      ,\n       0.22735344, 0.24221258, 0.25763221, 0.28146471, 0.26791659,\n       0.23951267, 0.21740042, 0.18660197, 0.49971815, 0.42036742,\n       0.45751686, 0.52951085, 0.49873228, 0.5       , 0.50028185,\n       0.3340115 , 0.43625295, 0.61242272, 0.55612717, 0.51078329,\n       0.50839542, 0.49859075, 0.9815    , 0.979     , 0.963     ,\n       0.411     , 0.489     , 0.505     , 0.588     , 0.4045    ,\n       0.9925    , 0.9945    , 0.6285    , 0.644     , 0.2845    ,\n       0.5335    , 0.5085    , 0.4525    , 0.4725    , 0.491     ,\n       0.533     , 0.4815    , 0.6295    , 0.5485    , 0.723     ,\n       0.5985    , 0.6275    , 0.10670996, 0.13266701, 0.16666667,\n       0.11666667, 0.11666667, 0.14278499, 0.17575758, 0.04542484,\n       0.23977874, 0.10653595, 0.10555556, 0.1       , 0.1010101 ,\n       0.09126984, 0.1530303 , 0.51879463, 0.5       , 0.5       ,\n       0.50074834, 0.52251271, 0.57665994, 0.51950409, 0.5       ,\n       0.5       , 0.50886804, 0.50907289, 0.50087376, 0.5       ,\n       0.5484542 , 0.51568902, 0.48085315, 0.50242082, 0.52736898,\n       0.56976266, 0.48660638, 0.43673598, 0.51152486, 0.55340793,\n       0.50050865, 0.51780264, 0.54069176, 0.85656155, 0.78992879,\n       0.53814852, 0.67192269, 0.7456765 , 0.5671414 , 0.50661241,\n       0.55035605, 0.50662106, 0.50082504, 0.49112769, 0.49747512,\n       0.5       , 0.5       , 0.4373466 , 0.4991791 , 0.5       ,\n       0.50334992, 0.5390796 , 0.50667081, 0.5       , 0.49669983,\n       0.44052653, 0.49243367, 0.43871061, 0.5       , 0.5       ,\n       0.9745    , 0.4405    , 0.5       , 0.5055    , 0.155     ,\n       0.511     , 0.625     , 0.4075    , 0.5       , 0.6125    ,\n       0.9715    , 0.541     , 0.267     , 0.891     , 0.5       ,\n       0.505     , 0.532     , 0.9495    , 0.618     , 0.4875    ,\n       0.5       , 0.28122126, 0.51443818, 0.77248807, 0.97539263,\n       0.50806941, 0.5       , 0.512     , 0.55431453, 0.44364859,\n       0.59157701, 0.5905    , 0.3975    , 0.5055    , 0.065     ,\n       0.518     , 0.5015    , 0.5855    , 0.771     , 0.53      ,\n       0.781     , 0.6215    , 0.6635    , 0.5075    , 0.5       ,\n       0.518     , 0.4995    , 0.47      , 0.4905    , 0.421     ,\n       0.913     , 0.5185    , 0.469     , 0.5       , 0.557     ,\n       0.397     , 0.5       , 0.66449511, 0.5       , 0.7752443 ,\n       0.90879479, 0.95276873, 0.51954397, 0.62540717, 0.5       ,\n       0.5       , 0.27687296, 0.69381108, 0.5       , 0.5       ,\n       0.34032323, 0.87842105, 0.33333333, 0.71733242, 0.40279151,\n       0.33540802, 0.33333333, 0.33333333, 0.33333333, 0.31120332,\n       0.33852005, 0.33506224, 0.64626556, 0.48201936, 0.9719917 ,\n       0.98063624, 0.98305671, 0.48191229, 0.49119486, 0.50893695,\n       0.49487916, 0.45781224, 0.54102163, 0.51706946, 0.49665371,\n       0.5       , 0.52813081, 0.47965185, 0.50507859, 0.49339615,\n       0.55125063, 0.53461214, 0.52618726, 0.87258519, 0.82083776,\n       0.81159569, 0.48572812, 0.46103528, 0.47091784, 0.49162894,\n       0.53839601, 0.56871129, 0.49860815, 0.44410754, 0.67763291,\n       0.5       , 0.53001819, 0.5640287 , 0.53623408, 0.98013948,\n       0.33333333, 0.36222129, 0.33333333, 0.39719502, 0.41868492,\n       0.5       , 0.49144369, 0.39839114, 0.54858476, 0.5       ,\n       0.58994693, 0.50054121, 0.95742551, 0.99043986, 0.96314352,\n       0.53486529, 0.99342687, 0.49785633, 0.47790117, 0.42924065,\n       0.5       , 0.5       , 0.5       , 0.49928775, 0.45472121,\n       0.36060236, 0.39555352, 0.4798026 , 0.78708791, 0.96306471,\n       0.50529101, 0.40713927, 0.1064857 , 0.12136121, 0.16047226,\n       0.10829671, 0.10037788, 0.09472391, 0.0743873 , 0.11471082,\n       0.22393333, 0.30466667, 0.3612    , 0.86833333, 0.24493333,\n       0.33446667, 0.33953333, 0.3342    , 0.33333333, 0.39907256,\n       0.55241862, 0.5279369 , 0.8061693 , 0.79634934, 0.48356519,\n       0.49777232, 0.47456356, 0.5       , 0.51304348, 0.5       ,\n       0.55434783, 0.54782609, 0.5       , 0.51304348, 0.48478261,\n       0.5       , 0.83043478, 0.41086956, 0.45869565, 0.49782609,\n       0.5       , 0.5       , 0.5       , 0.51521739, 0.35472137,\n       0.21612731, 0.13886788, 0.14216731, 0.17331563, 0.2       ,\n       0.17239298, 0.20778464, 0.32904235, 0.19981003, 0.32824385,\n       0.21571892, 0.22096705, 0.63221925, 0.16311228, 0.3104212 ,\n       0.25      , 0.3076343 , 0.29985158, 0.25167821, 0.25821879,\n       0.29862074, 0.29129492, 0.68112438, 0.24656701, 0.25      ,\n       0.2870729 , 0.5441009 , 0.28508483, 0.20651175, 0.2784558 ,\n       0.21116537, 0.28984456, 0.19746363, 0.22289061, 0.27570431,\n       0.22727782, 0.25      , 0.2456808 , 0.22950423, 0.20104712,\n       0.87360432, 0.2       , 0.12400715, 0.2       , 0.92616809,\n       0.35978839, 0.38513586, 0.38261111, 0.25093045, 0.37270709,\n       0.36853391, 0.2059417 , 0.38085099, 0.14260435, 0.14156519,\n       0.14507661, 0.14950802, 0.13929377, 0.12647306, 0.16725519,\n       0.14285714, 0.46435579, 0.50032701, 0.50032701, 0.52877698,\n       0.49345978, 0.56736429, 0.4440811 , 0.50098103, 0.47580118,\n       0.49771092, 0.49967299, 0.5       , 0.51219512, 0.72073171,\n       0.54682927, 0.3546786 , 0.46833333, 0.25      , 0.45520734,\n       0.25      , 0.44963263, 0.23221043, 0.49781211, 0.06931565,\n       0.36866667, 0.23558647, 0.26024931, 0.25      , 0.24318644,\n       0.26320928, 0.30448397, 0.27105487, 0.19935429, 0.25      ,\n       0.25      , 0.60833333, 0.36      , 0.5       , 0.49333333,\n       0.5       , 0.47833333, 0.5       , 0.5       , 0.5       ,\n       0.5       , 0.47833333, 0.45833333, 0.5       , 0.5       ,\n       1.        , 0.99666667, 1.        , 0.38666667, 0.305     ,\n       0.62      , 0.655     , 0.01666667, 0.49      , 0.64      ,\n       0.59666667, 0.51333333, 0.5       , 0.125     , 0.64705632,\n       0.70814888, 0.24390655, 0.11157674, 0.125     , 0.10177003,\n       0.09429559, 0.14511289, 0.14216507, 0.125     , 0.125     ,\n       0.125     , 0.13509266, 0.125     , 0.125     , 0.1818219 ,\n       0.0773381 , 0.125     , 0.11846405, 0.125     , 0.1946    ,\n       0.36866535, 0.23219208, 0.2       , 0.2       , 0.28930297,\n       0.1976    , 0.092     , 0.2       , 0.5       , 0.5       ,\n       0.45543121, 0.48979592, 0.42804477, 0.50645161, 0.53884134,\n       0.18872536, 0.17250909, 0.17922446, 0.19122835, 0.17574054,\n       0.17935401, 0.15039924, 0.17886393, 0.1906602 , 0.1921537 ,\n       0.19927349, 0.16666667, 0.36081062, 0.92934731, 0.93928284,\n       0.85687068, 0.87728016, 0.94349209, 0.79388687, 0.49898125,\n       0.49953194, 0.5       , 0.50383448, 0.5       , 0.26882286,\n       0.02906977, 0.31101248, 0.21972011, 0.25      , 0.25794789,\n       0.18034251, 0.13924219, 0.2538657 , 0.01046512, 0.92065107,\n       0.48626653, 0.48677518, 0.50101729, 0.85656155, 0.62309257,\n       0.69532045, 0.74618515, 0.7456765 , 0.63123093, 0.58799593,\n       0.18621695, 0.15651057, 0.11987578, 0.18853017, 0.19865736,\n       0.14397468, 0.78760923, 0.92476521, 0.79891313, 0.54635836,\n       0.80043098, 0.9147422 , 0.10416894, 0.14895251, 0.15543902,\n       0.15346663, 0.16666667, 0.50122597, 0.52719069, 0.5       ,\n       0.5       , 0.5       , 0.50078729, 0.5       , 0.5       ,\n       0.98974478, 0.62777778, 0.59305556, 0.50555556, 0.32638889,\n       0.8472054 , 0.86568999, 0.23626313, 0.34027778, 0.39861111,\n       0.40138889, 0.37638889, 0.34166667, 0.22      , 0.224     ,\n       0.232     , 0.2       , 0.3       , 0.245     , 0.25      ,\n       0.248     , 0.256     , 0.204     , 0.9928    , 0.9632    ,\n       0.5       , 0.5       , 0.5042    , 0.393     , 0.443     ,\n       0.5012    , 0.779     , 0.9954    , 0.992     , 0.9758    ,\n       0.5376    , 0.508     , 0.5       , 0.3052    , 0.4978    ,\n       0.471     , 0.4936    , 0.5732    , 0.4772    , 0.7228    ,\n       0.553     , 0.4416    , 0.5104    , 0.4606    , 0.33491031,\n       0.27261975, 0.33333333, 0.33333333, 0.99881727, 0.99862015,\n       0.26389741, 0.26907797, 0.33333333, 0.34998168, 0.44439559,\n       0.36753809, 0.55448029, 0.4124222 , 0.50105654, 0.48729558,\n       0.33437768, 0.33333333, 0.33299914, 0.26869645, 0.23104684,\n       0.25      , 0.28923388, 0.25026681, 0.25      , 0.26734258,\n       0.30570467, 0.25      , 0.23586787, 0.24507304, 0.30792498,\n       0.16489877, 0.17557961, 0.09071153, 0.20150768, 0.29677177,\n       0.23299862, 0.21235574, 0.19865736, 0.23390274, 0.16702996,\n       0.22243344, 0.16666667, 0.26636297, 0.7830901 , 0.4765    ,\n       0.761     , 0.6055    , 0.715     , 0.547     , 0.4915    ,\n       0.4965    , 0.532     , 0.5535    , 0.5065    , 0.1295    ,\n       0.5345    , 0.4545    , 0.7805    , 0.5125    , 0.5       ,\n       0.5975    , 0.3245    , 0.6245    , 0.621     , 0.612     ,\n       0.621     , 0.6385    , 0.07018957, 0.12304778, 0.10385665,\n       0.1       , 0.55670728, 0.13863185, 0.1027413 , 0.13962223,\n       0.1       , 0.1       , 0.06605529, 0.9       , 0.77857143,\n       0.89285714, 0.73214286, 0.91428571, 0.79285714, 0.5       ,\n       0.625     , 0.5       , 0.5       , 0.5       , 0.5       ,\n       0.5       , 0.77857143, 0.37758744, 0.1359743 , 0.22947894,\n       0.33940043, 0.44254104, 0.5       , 0.49841519, 0.51460416,\n       0.4124222 , 0.5       , 0.50697392, 0.94355165, 0.57787548,\n       0.50245098, 0.73382858, 0.96775824, 0.57878512, 0.93281282,\n       0.88773499, 0.90726682, 0.95357819, 0.57135373, 0.39317377,\n       0.5       , 0.48926474, 0.49851528, 0.5       , 0.50502014,\n       0.48456586, 0.98961913, 0.70940895, 0.97973526, 0.96786729,\n       0.49108326, 0.5079501 , 0.5174044 , 0.39793595, 0.5       ,\n       0.5231236 , 0.50742329, 0.77019779, 0.9891231 , 0.6382285 ,\n       0.61929204, 0.9822066 , 0.51714002, 0.50956377, 0.31386957,\n       0.49130366, 0.91295796, 0.61695314, 0.51926487, 0.5       ,\n       0.54593689, 0.39723809, 0.52016358, 0.50664186, 0.108     ,\n       0.0995    , 0.1492    , 0.10591759, 0.11461838, 0.08082189,\n       0.93013895, 0.1       , 0.33333333, 0.25506667, 0.3316    ,\n       0.1958    , 0.32246667, 0.33033333, 0.336     , 0.5553945 ,\n       0.4997995 , 0.44800605, 0.4126659 , 0.53700896, 0.43352248,\n       0.5       , 0.48821743, 0.25961949, 0.22280432, 0.16948334,\n       0.18907978, 0.2558901 , 0.1815679 , 0.12591041, 0.22038061,\n       0.22640621, 0.22656451, 0.17772129, 0.20402749, 0.77304609,\n       0.93154499, 0.97650194, 0.50055494, 0.50499445, 0.60672762,\n       0.50281796, 0.5057676 , 0.44040332, 0.30222791, 0.33410147,\n       0.56794146, 0.59119873, 0.50692639, 0.5       , 0.5       ,\n       0.34015243, 0.33667133, 0.32241153, 0.32607859, 0.33651533,\n       0.31549633, 0.41405082, 0.81747463, 0.50719187, 0.49501679,\n       0.53680537, 0.51086541, 0.48323725, 0.51353019, 0.51614955,\n       0.49894204, 0.50252662, 0.54459531, 0.56633748, 0.49854838,\n       0.53296907, 0.49902153, 0.48586607, 0.54709921, 0.49893257,\n       0.5159054 , 0.49984859, 0.5       , 0.47339195, 0.48821668,\n       0.78093547, 0.83516032, 0.79202799, 0.52903436, 0.25      ,\n       0.25      , 0.25412009, 0.15786069, 0.25      , 0.26306823,\n       0.25      , 0.22017739, 0.25      , 0.18981438, 0.17250909,\n       0.20610082, 0.16666667, 0.16858731, 0.17874869, 0.10427003,\n       0.14355749, 0.21989148, 0.16895659, 0.27492919, 0.15238891,\n       0.17917806])"
     },
     "execution_count": 1803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_test[data_model_test.nonzero()].flatten()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1804,
   "outputs": [],
   "source": [
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction.to_numpy()[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction,ground_truth))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1805,
   "outputs": [
    {
     "data": {
      "text/plain": "'0.21925287250403064'"
     },
     "execution_count": 1805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(rmse(model_prediction_csv,data_model_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1806,
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "outputs": [
    {
     "data": {
      "text/plain": "      dataset_id  model_id  balance_accuracy\n0              0        72          0.940459\n6              0        78          0.999439\n7              0        79          0.999720\n9              0        81          0.999439\n11             0        83          0.560429\n...          ...       ...               ...\n9222          71      1165          0.219891\n9258          71      1451          0.168957\n9261          71      1454          0.274929\n9270          71      1463          0.152389\n9282          71      1850          0.179178\n\n[931 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9222</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n    </tr>\n    <tr>\n      <th>9258</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n    </tr>\n    <tr>\n      <th>9261</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n    </tr>\n    <tr>\n      <th>9270</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n    </tr>\n    <tr>\n      <th>9282</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = test_data.sort_index()\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1808,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy\n0             0        72          0.940459\n1             0        78          0.999439\n2             0        79          0.999720\n3             0        81          0.999439\n4             0        83          0.560429\n..          ...       ...               ...\n926          71      1165          0.219891\n927          71      1451          0.168957\n928          71      1454          0.274929\n929          71      1463          0.152389\n930          71      1850          0.179178\n\n[931 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1808,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = prediction.reset_index()\n",
    "result = result.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# pd.merge(result, prediction)\n",
    "result\n",
    "\n",
    "# prediction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1809,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  dataset_id  model_id  balance_accuracy\n0        0           0        72          0.940459\n1        1           0        78          0.999439\n2        2           0        79          0.999720\n3        3           0        81          0.999439\n4        4           0        83          0.560429\n..     ...         ...       ...               ...\n926    926          71      1165          0.219891\n927    927          71      1451          0.168957\n928    928          71      1454          0.274929\n929    929          71      1463          0.152389\n930    930          71      1850          0.179178\n\n[931 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 1809,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index()\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1810,
   "outputs": [
    {
     "data": {
      "text/plain": "     index_1  dataset_id  model_id  balance_accuracy  index_2         0\n0          0           0        72          0.940459        0  0.119379\n1          1           0        78          0.999439        1  0.342999\n2          2           0        79          0.999720        2  0.359339\n3          3           0        81          0.999439        3  0.385896\n4          4           0        83          0.560429        4  0.267001\n..       ...         ...       ...               ...      ...       ...\n926      926          71      1165          0.219891      926  0.179248\n927      927          71      1451          0.168957      927  0.312657\n928      928          71      1454          0.274929      928  0.355665\n929      929          71      1463          0.152389      929  0.325650\n930      930          71      1850          0.179178      930  0.137795\n\n[931 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index_1</th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>index_2</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0</td>\n      <td>0.119379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>1</td>\n      <td>0.342999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>2</td>\n      <td>0.359339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>3</td>\n      <td>0.385896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>4</td>\n      <td>0.267001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>926</td>\n      <td>0.179248</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>927</td>\n      <td>0.312657</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>928</td>\n      <td>0.355665</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>929</td>\n      <td>0.325650</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>930</td>\n      <td>0.137795</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 1810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.join(prediction,on='index',lsuffix='_1',rsuffix='_2')\n",
    "# result.drop('index_2')\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1811,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy         0\n0             0        72          0.940459  0.119379\n1             0        78          0.999439  0.342999\n2             0        79          0.999720  0.359339\n3             0        81          0.999439  0.385896\n4             0        83          0.560429  0.267001\n..          ...       ...               ...       ...\n926          71      1165          0.219891  0.179248\n927          71      1451          0.168957  0.312657\n928          71      1454          0.274929  0.355665\n929          71      1463          0.152389  0.325650\n930          71      1850          0.179178  0.137795\n\n[931 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 1811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.drop(['index_1', 'index_2'], axis=1, inplace=True)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1812,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy  prediction\n0             0        72          0.940459    0.119379\n1             0        78          0.999439    0.342999\n2             0        79          0.999720    0.359339\n3             0        81          0.999439    0.385896\n4             0        83          0.560429    0.267001\n..          ...       ...               ...         ...\n926          71      1165          0.219891    0.179248\n927          71      1451          0.168957    0.312657\n928          71      1454          0.274929    0.355665\n929          71      1463          0.152389    0.325650\n930          71      1850          0.179178    0.137795\n\n[931 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 1812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.rename(columns={'level_0':'id', 0: 'prediction'})\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1813,
   "outputs": [],
   "source": [
    "result = result[['dataset_id', 'model_id', 'balance_accuracy', 'prediction']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1814,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy  prediction\n0             0        72          0.940459    0.119379\n1             0        78          0.999439    0.342999\n2             0        79          0.999720    0.359339\n3             0        81          0.999439    0.385896\n4             0        83          0.560429    0.267001\n..          ...       ...               ...         ...\n926          71      1165          0.219891    0.179248\n927          71      1451          0.168957    0.312657\n928          71      1454          0.274929    0.355665\n929          71      1463          0.152389    0.325650\n930          71      1850          0.179178    0.137795\n\n[931 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 1814,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1815,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  dataset_id  model_id  balance_accuracy  prediction\n0        0           0        72          0.940459    0.119379\n1        1           0        78          0.999439    0.342999\n2        2           0        79          0.999720    0.359339\n3        3           0        81          0.999439    0.385896\n4        4           0        83          0.560429    0.267001\n..     ...         ...       ...               ...         ...\n926    926          71      1165          0.219891    0.179248\n927    927          71      1451          0.168957    0.312657\n928    928          71      1454          0.274929    0.355665\n929    929          71      1463          0.152389    0.325650\n930    930          71      1850          0.179178    0.137795\n\n[931 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 1815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1816,
   "outputs": [
    {
     "data": {
      "text/plain": "        72        73        74        75        76        77        78    \\\n0   0.119379  0.536762  0.515269  0.712684  0.680991  0.646880  0.342999   \n1   0.004725  0.004725  0.004725  0.004725  0.004725  0.004725  0.004725   \n2  -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885   \n3  -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501   \n4  -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484   \n..       ...       ...       ...       ...       ...       ...       ...   \n67  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749   \n68  0.133121  0.488279  0.465811  0.669896  0.634873  0.599598  0.364033   \n69 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916   \n70 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122   \n71 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827   \n\n        79        80        81    ...      1612      1613      1614      1615  \\\n0   0.359339  0.709832  0.385896  ...  0.001806  0.001806  0.001806  0.001806   \n1   0.004725  0.004725  0.004725  ...  0.004725  0.004725  0.004725  0.004725   \n2  -0.001885 -0.001885 -0.001885  ... -0.001885 -0.001885 -0.001885 -0.001885   \n3  -0.002501 -0.002501 -0.002501  ... -0.002501 -0.002501 -0.002501 -0.002501   \n4  -0.003484 -0.003484 -0.003484  ... -0.003484 -0.003484 -0.003484 -0.003484   \n..       ...       ...       ...  ...       ...       ...       ...       ...   \n67  0.001749  0.001749  0.001749  ...  0.001749  0.001749  0.001749  0.001749   \n68  0.380045  0.665515  0.409165  ... -0.003134 -0.003134 -0.003134 -0.003134   \n69 -0.003916 -0.003916 -0.003916  ... -0.003916 -0.003916 -0.003916 -0.003916   \n70 -0.000122 -0.000122 -0.000122  ... -0.000122 -0.000122 -0.000122 -0.000122   \n71 -0.003827 -0.003827 -0.003827  ... -0.003827 -0.003827 -0.003827 -0.003827   \n\n        1616      1617      1618      1619      1620      1621  \n0   0.001806  0.001806  0.001806  0.001806  0.001806  0.001806  \n1   0.004725  0.004725  0.004725  0.004725  0.004725  0.004725  \n2  -0.001885 -0.001885 -0.001885 -0.001885 -0.001885 -0.001885  \n3  -0.002501 -0.002501 -0.002501 -0.002501 -0.002501 -0.002501  \n4  -0.003484 -0.003484 -0.003484 -0.003484 -0.003484 -0.003484  \n..       ...       ...       ...       ...       ...       ...  \n67  0.001749  0.001749  0.001749  0.001749  0.001749  0.001749  \n68 -0.003134 -0.003134 -0.003134 -0.003134 -0.003134 -0.003134  \n69 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916 -0.003916  \n70 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122 -0.000122  \n71 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827 -0.003827  \n\n[72 rows x 1800 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>...</th>\n      <th>1612</th>\n      <th>1613</th>\n      <th>1614</th>\n      <th>1615</th>\n      <th>1616</th>\n      <th>1617</th>\n      <th>1618</th>\n      <th>1619</th>\n      <th>1620</th>\n      <th>1621</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.119379</td>\n      <td>0.536762</td>\n      <td>0.515269</td>\n      <td>0.712684</td>\n      <td>0.680991</td>\n      <td>0.646880</td>\n      <td>0.342999</td>\n      <td>0.359339</td>\n      <td>0.709832</td>\n      <td>0.385896</td>\n      <td>...</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>...</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>...</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>...</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>...</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>...</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n      <td>0.001749</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>0.133121</td>\n      <td>0.488279</td>\n      <td>0.465811</td>\n      <td>0.669896</td>\n      <td>0.634873</td>\n      <td>0.599598</td>\n      <td>0.364033</td>\n      <td>0.380045</td>\n      <td>0.665515</td>\n      <td>0.409165</td>\n      <td>...</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n      <td>-0.003134</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>...</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n      <td>-0.003916</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>...</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n      <td>-0.000122</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>...</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n      <td>-0.003827</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 1800 columns</p>\n</div>"
     },
     "execution_count": 1816,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prediction_csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1817,
   "outputs": [
    {
     "data": {
      "text/plain": "      dataset_id  model_id  balance_accuracy   rank\n0              0        72          0.940459   17.0\n1              0        73          0.958896   15.0\n2              0        74          0.958319   16.0\n3              0        75          0.999720    2.5\n4              0        76          0.999439    5.0\n...          ...       ...               ...    ...\n9299          71      1867          0.168099  103.0\n9300          71      1868          0.166667  109.0\n9301          71      1869          0.343778    8.0\n9302          71      1870          0.360811    6.0\n9303          71      1871          0.165255  117.0\n\n[9304 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>73</td>\n      <td>0.958896</td>\n      <td>15.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>74</td>\n      <td>0.958319</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>75</td>\n      <td>0.999720</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>76</td>\n      <td>0.999439</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9299</th>\n      <td>71</td>\n      <td>1867</td>\n      <td>0.168099</td>\n      <td>103.0</td>\n    </tr>\n    <tr>\n      <th>9300</th>\n      <td>71</td>\n      <td>1868</td>\n      <td>0.166667</td>\n      <td>109.0</td>\n    </tr>\n    <tr>\n      <th>9301</th>\n      <td>71</td>\n      <td>1869</td>\n      <td>0.343778</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>9302</th>\n      <td>71</td>\n      <td>1870</td>\n      <td>0.360811</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>9303</th>\n      <td>71</td>\n      <td>1871</td>\n      <td>0.165255</td>\n      <td>117.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>9304 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 1817,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['rank'] =ratings.groupby(['dataset_id'])['balance_accuracy'].rank(ascending=False)\n",
    "ratings"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1818,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy  prediction   rank\n0             0        72          0.940459    0.119379   17.0\n1             0        78          0.999439    0.342999    5.0\n2             0        79          0.999720    0.359339    2.5\n3             0        81          0.999439    0.385896    5.0\n4             0        83          0.560429    0.267001   29.0\n..          ...       ...               ...         ...    ...\n926          71      1165          0.219891    0.179248   24.0\n927          71      1451          0.168957    0.312657   95.0\n928          71      1454          0.274929    0.355665   10.0\n929          71      1463          0.152389    0.325650  132.0\n930          71      1850          0.179178    0.137795   68.0\n\n[931 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n      <th>rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n      <td>68.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 1818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.merge(result, ratings, how='left',\n",
    "                    left_on=['dataset_id', 'model_id', 'balance_accuracy'], right_on=['dataset_id', 'model_id','balance_accuracy'],\n",
    "                    sort=False, suffixes=('', '_t'))\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1819,
   "outputs": [
    {
     "data": {
      "text/plain": "     dataset_id  model_id  balance_accuracy  prediction  rank_gt\n0             0        72          0.940459    0.119379     17.0\n1             0        78          0.999439    0.342999      5.0\n2             0        79          0.999720    0.359339      2.5\n3             0        81          0.999439    0.385896      5.0\n4             0        83          0.560429    0.267001     29.0\n..          ...       ...               ...         ...      ...\n926          71      1165          0.219891    0.179248     24.0\n927          71      1451          0.168957    0.312657     95.0\n928          71      1454          0.274929    0.355665     10.0\n929          71      1463          0.152389    0.325650    132.0\n930          71      1850          0.179178    0.137795     68.0\n\n[931 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n      <th>rank_gt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n      <td>132.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n      <td>68.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 1819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.rename(columns={'rank':'rank_gt'})\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1820,
   "outputs": [
    {
     "data": {
      "text/plain": "             0         1         2         3         4         5         6  \\\n72    0.119379  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n73    0.536762  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n74    0.515269  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n75    0.712684  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n76    0.680991  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n...        ...       ...       ...       ...       ...       ...       ...   \n1617  0.001806  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n1618  0.001806  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n1619  0.001806  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n1620  0.001806  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n1621  0.001806  0.004725 -0.001885 -0.002501 -0.003484 -0.001243  0.002152   \n\n             7         8        9  ...  62rank  63rank  64rank  65rank  \\\n72    0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n73    0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n74    0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n75    0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n76    0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n...        ...       ...      ...  ...     ...     ...     ...     ...   \n1617  0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n1618  0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n1619  0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n1620  0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n1621  0.001497 -0.007327 -0.00428  ...  1025.5   950.5   950.5   938.0   \n\n      66rank  67rank  68rank  69rank  70rank  71rank  \n72     950.5   975.5    99.0  1025.5   950.5   975.5  \n73     950.5   975.5    15.0  1025.5   950.5   975.5  \n74     950.5   975.5    17.0  1025.5   950.5   975.5  \n75     950.5   975.5     2.0  1025.5   950.5   975.5  \n76     950.5   975.5     4.0  1025.5   950.5   975.5  \n...      ...     ...     ...     ...     ...     ...  \n1617   950.5   975.5   950.5  1025.5   950.5   975.5  \n1618   950.5   975.5   950.5  1025.5   950.5   975.5  \n1619   950.5   975.5   950.5  1025.5   950.5   975.5  \n1620   950.5   975.5   950.5  1025.5   950.5   975.5  \n1621   950.5   975.5   950.5  1025.5   950.5   975.5  \n\n[1800 rows x 144 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>62rank</th>\n      <th>63rank</th>\n      <th>64rank</th>\n      <th>65rank</th>\n      <th>66rank</th>\n      <th>67rank</th>\n      <th>68rank</th>\n      <th>69rank</th>\n      <th>70rank</th>\n      <th>71rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72</th>\n      <td>0.119379</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>99.0</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>0.536762</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>15.0</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.515269</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>17.0</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>0.712684</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>2.0</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>0.680991</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>4.0</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1617</th>\n      <td>0.001806</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>950.5</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>1618</th>\n      <td>0.001806</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>950.5</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>1619</th>\n      <td>0.001806</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>950.5</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>1620</th>\n      <td>0.001806</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>950.5</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>1621</th>\n      <td>0.001806</td>\n      <td>0.004725</td>\n      <td>-0.001885</td>\n      <td>-0.002501</td>\n      <td>-0.003484</td>\n      <td>-0.001243</td>\n      <td>0.002152</td>\n      <td>0.001497</td>\n      <td>-0.007327</td>\n      <td>-0.00428</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>938.0</td>\n      <td>950.5</td>\n      <td>975.5</td>\n      <td>950.5</td>\n      <td>1025.5</td>\n      <td>950.5</td>\n      <td>975.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>1800 rows × 144 columns</p>\n</div>"
     },
     "execution_count": 1820,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = model_prediction_csv.T\n",
    "\n",
    "for index, row in test.iteritems():\n",
    "    new_row = str(index) + 'rank'\n",
    "    test[new_row] = test[index].rank(ascending=False)\n",
    "test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1821,
   "outputs": [
    {
     "data": {
      "text/plain": "               72           73           74           75           76    \\\n0          0.119379     0.536762     0.515269     0.712684     0.680991   \n1          0.004725     0.004725     0.004725     0.004725     0.004725   \n2         -0.001885    -0.001885    -0.001885    -0.001885    -0.001885   \n3         -0.002501    -0.002501    -0.002501    -0.002501    -0.002501   \n4         -0.003484    -0.003484    -0.003484    -0.003484    -0.003484   \n...             ...          ...          ...          ...          ...   \n67rank   975.500000   975.500000   975.500000   975.500000   975.500000   \n68rank    99.000000    15.000000    17.000000     2.000000     4.000000   \n69rank  1025.500000  1025.500000  1025.500000  1025.500000  1025.500000   \n70rank   950.500000   950.500000   950.500000   950.500000   950.500000   \n71rank   975.500000   975.500000   975.500000   975.500000   975.500000   \n\n               77           78           79           80           81    ...  \\\n0          0.646880     0.342999     0.359339     0.709832     0.385896  ...   \n1          0.004725     0.004725     0.004725     0.004725     0.004725  ...   \n2         -0.001885    -0.001885    -0.001885    -0.001885    -0.001885  ...   \n3         -0.002501    -0.002501    -0.002501    -0.002501    -0.002501  ...   \n4         -0.003484    -0.003484    -0.003484    -0.003484    -0.003484  ...   \n...             ...          ...          ...          ...          ...  ...   \n67rank   975.500000   975.500000   975.500000   975.500000   975.500000  ...   \n68rank     5.000000    45.000000    38.000000     3.000000    27.000000  ...   \n69rank  1025.500000  1025.500000  1025.500000  1025.500000  1025.500000  ...   \n70rank   950.500000   950.500000   950.500000   950.500000   950.500000  ...   \n71rank   975.500000   975.500000   975.500000   975.500000   975.500000  ...   \n\n               1612         1613         1614         1615         1616  \\\n0          0.001806     0.001806     0.001806     0.001806     0.001806   \n1          0.004725     0.004725     0.004725     0.004725     0.004725   \n2         -0.001885    -0.001885    -0.001885    -0.001885    -0.001885   \n3         -0.002501    -0.002501    -0.002501    -0.002501    -0.002501   \n4         -0.003484    -0.003484    -0.003484    -0.003484    -0.003484   \n...             ...          ...          ...          ...          ...   \n67rank   975.500000   975.500000   975.500000   975.500000   975.500000   \n68rank   950.500000   950.500000   950.500000   950.500000   950.500000   \n69rank  1025.500000  1025.500000  1025.500000  1025.500000  1025.500000   \n70rank   950.500000   950.500000   950.500000   950.500000   950.500000   \n71rank   975.500000   975.500000   975.500000   975.500000   975.500000   \n\n               1617         1618         1619         1620         1621  \n0          0.001806     0.001806     0.001806     0.001806     0.001806  \n1          0.004725     0.004725     0.004725     0.004725     0.004725  \n2         -0.001885    -0.001885    -0.001885    -0.001885    -0.001885  \n3         -0.002501    -0.002501    -0.002501    -0.002501    -0.002501  \n4         -0.003484    -0.003484    -0.003484    -0.003484    -0.003484  \n...             ...          ...          ...          ...          ...  \n67rank   975.500000   975.500000   975.500000   975.500000   975.500000  \n68rank   950.500000   950.500000   950.500000   950.500000   950.500000  \n69rank  1025.500000  1025.500000  1025.500000  1025.500000  1025.500000  \n70rank   950.500000   950.500000   950.500000   950.500000   950.500000  \n71rank   975.500000   975.500000   975.500000   975.500000   975.500000  \n\n[144 rows x 1800 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>...</th>\n      <th>1612</th>\n      <th>1613</th>\n      <th>1614</th>\n      <th>1615</th>\n      <th>1616</th>\n      <th>1617</th>\n      <th>1618</th>\n      <th>1619</th>\n      <th>1620</th>\n      <th>1621</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.119379</td>\n      <td>0.536762</td>\n      <td>0.515269</td>\n      <td>0.712684</td>\n      <td>0.680991</td>\n      <td>0.646880</td>\n      <td>0.342999</td>\n      <td>0.359339</td>\n      <td>0.709832</td>\n      <td>0.385896</td>\n      <td>...</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n      <td>0.001806</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>...</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n      <td>0.004725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>...</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n      <td>-0.001885</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>...</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n      <td>-0.002501</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>...</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n      <td>-0.003484</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67rank</th>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>...</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n    </tr>\n    <tr>\n      <th>68rank</th>\n      <td>99.000000</td>\n      <td>15.000000</td>\n      <td>17.000000</td>\n      <td>2.000000</td>\n      <td>4.000000</td>\n      <td>5.000000</td>\n      <td>45.000000</td>\n      <td>38.000000</td>\n      <td>3.000000</td>\n      <td>27.000000</td>\n      <td>...</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n    </tr>\n    <tr>\n      <th>69rank</th>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>...</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n      <td>1025.500000</td>\n    </tr>\n    <tr>\n      <th>70rank</th>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>...</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n      <td>950.500000</td>\n    </tr>\n    <tr>\n      <th>71rank</th>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>...</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n      <td>975.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>144 rows × 1800 columns</p>\n</div>"
     },
     "execution_count": 1821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.T\n",
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1822,
   "outputs": [
    {
     "data": {
      "text/plain": "          72      73      74      75      76      77      78      79    \\\n0rank     99.0    13.0    16.0     2.0     4.0     5.0    48.0    44.0   \n1rank   1025.5  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5   \n2rank    950.5   950.5   950.5   950.5   950.5   950.5   950.5   950.5   \n3rank    975.5   975.5   975.5   975.5   975.5   975.5   975.5   975.5   \n4rank    975.5   975.5   975.5   975.5   975.5   975.5   975.5   975.5   \n...        ...     ...     ...     ...     ...     ...     ...     ...   \n67rank   975.5   975.5   975.5   975.5   975.5   975.5   975.5   975.5   \n68rank    99.0    15.0    17.0     2.0     4.0     5.0    45.0    38.0   \n69rank  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5   \n70rank   950.5   950.5   950.5   950.5   950.5   950.5   950.5   950.5   \n71rank   975.5   975.5   975.5   975.5   975.5   975.5   975.5   975.5   \n\n          80      81    ...    1612    1613    1614    1615    1616    1617  \\\n0rank      3.0    36.0  ...   950.5   950.5   950.5   950.5   950.5   950.5   \n1rank   1025.5  1025.5  ...  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5   \n2rank    950.5   950.5  ...   950.5   950.5   950.5   950.5   950.5   950.5   \n3rank    975.5   975.5  ...   975.5   975.5   975.5   975.5   975.5   975.5   \n4rank    975.5   975.5  ...   975.5   975.5   975.5   975.5   975.5   975.5   \n...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n67rank   975.5   975.5  ...   975.5   975.5   975.5   975.5   975.5   975.5   \n68rank     3.0    27.0  ...   950.5   950.5   950.5   950.5   950.5   950.5   \n69rank  1025.5  1025.5  ...  1025.5  1025.5  1025.5  1025.5  1025.5  1025.5   \n70rank   950.5   950.5  ...   950.5   950.5   950.5   950.5   950.5   950.5   \n71rank   975.5   975.5  ...   975.5   975.5   975.5   975.5   975.5   975.5   \n\n          1618    1619    1620    1621  \n0rank    950.5   950.5   950.5   950.5  \n1rank   1025.5  1025.5  1025.5  1025.5  \n2rank    950.5   950.5   950.5   950.5  \n3rank    975.5   975.5   975.5   975.5  \n4rank    975.5   975.5   975.5   975.5  \n...        ...     ...     ...     ...  \n67rank   975.5   975.5   975.5   975.5  \n68rank   950.5   950.5   950.5   950.5  \n69rank  1025.5  1025.5  1025.5  1025.5  \n70rank   950.5   950.5   950.5   950.5  \n71rank   975.5   975.5   975.5   975.5  \n\n[72 rows x 1800 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>72</th>\n      <th>73</th>\n      <th>74</th>\n      <th>75</th>\n      <th>76</th>\n      <th>77</th>\n      <th>78</th>\n      <th>79</th>\n      <th>80</th>\n      <th>81</th>\n      <th>...</th>\n      <th>1612</th>\n      <th>1613</th>\n      <th>1614</th>\n      <th>1615</th>\n      <th>1616</th>\n      <th>1617</th>\n      <th>1618</th>\n      <th>1619</th>\n      <th>1620</th>\n      <th>1621</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0rank</th>\n      <td>99.0</td>\n      <td>13.0</td>\n      <td>16.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>48.0</td>\n      <td>44.0</td>\n      <td>3.0</td>\n      <td>36.0</td>\n      <td>...</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n    </tr>\n    <tr>\n      <th>1rank</th>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n    </tr>\n    <tr>\n      <th>2rank</th>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>...</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n    </tr>\n    <tr>\n      <th>3rank</th>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>...</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>4rank</th>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>...</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67rank</th>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>...</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n    </tr>\n    <tr>\n      <th>68rank</th>\n      <td>99.0</td>\n      <td>15.0</td>\n      <td>17.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>45.0</td>\n      <td>38.0</td>\n      <td>3.0</td>\n      <td>27.0</td>\n      <td>...</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n    </tr>\n    <tr>\n      <th>69rank</th>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>...</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n      <td>1025.5</td>\n    </tr>\n    <tr>\n      <th>70rank</th>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>...</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n      <td>950.5</td>\n    </tr>\n    <tr>\n      <th>71rank</th>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>...</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n      <td>975.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>72 rows × 1800 columns</p>\n</div>"
     },
     "execution_count": 1822,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[72:]\n",
    "test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1823,
   "outputs": [
    {
     "data": {
      "text/plain": "0rank      950.5\n1rank     1025.5\n2rank      950.5\n3rank      127.0\n4rank      975.5\n           ...  \n67rank     975.5\n68rank     950.5\n69rank    1025.5\n70rank     950.5\n71rank     111.0\nName: 1870, Length: 72, dtype: float64"
     },
     "execution_count": 1823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[1870]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1824,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 99. ,  48. ,  44. ,  36. ,  83. ,  40. ,  88. , 100. ,  98. ,\n        73. ,  89. ,  50. ,  20. , 145. , 222. , 226. ,  37. ,  40. ,\n       176. , 244. , 185. , 200. , 210. ,  81. , 217. , 121. , 199. ,\n       220. ,  94. ,  38. ,  43. ,  39. ,  98. ,  91. ,  93. , 100. ,\n        97. ,  19. ,  31. ,  83. ,  89. ,  90. ,  37. ,  41. ,  66. ,\n        40. , 143. ,  99. , 123. ,  95. , 119. , 148. ,  98. , 150. ,\n        54. , 116. ,  46. ,  19. ,  20. ,  39. , 136. , 140. , 141. ,\n       139. , 127. , 142. , 136. , 120. , 104. , 144. , 129. , 126. ,\n        93. ,  96. , 118. , 124. , 143. , 122. , 132. , 117. ,  64. ,\n       135. ,  91. ,  95. ,  94. ,  90. ,  96. ,  88. ,  99. ,   5. ,\n        93. , 100. ,  81. , 122.5, 143. , 145. , 126. , 129. , 122.5,\n       122.5,  99. , 133. ,  87. , 130. , 137. , 148. , 122.5, 147. ,\n        33. ,  35. , 246. , 220. , 221. , 230. , 243. ,  75. ,  22. ,\n       235. , 226. , 247. , 136. , 160. , 158. , 122. , 148. , 174. ,\n       214. , 175. , 168. , 187. , 222. , 152. ,  21. ,  82. ,  40. ,\n        35. ,  43. ,   4. ,   6. ,  98. ,  99. ,  77. ,  79. ,  88. ,\n        65. ,  27. ,  94. ,  20. , 244. , 179. , 250. ,  60. , 200. ,\n        12. , 220. , 221. , 204. , 164. , 132. , 223. , 188. , 208. ,\n       225. ,  11. , 232. , 217. , 224. , 219. , 184. ,  73. ,  68. ,\n        65. ,  75. ,  71. ,  27. ,  58. ,  51. ,  70. ,  59. ,  69. ,\n        74. ,  28. ,  27. , 149. , 148. , 121. , 120. , 134. , 141. ,\n       123. , 144. , 127. , 122. , 140. , 107. , 125. , 143. , 137. ,\n       150. , 124. ,  32. , 230. , 240. , 244. , 249. , 226. , 144. ,\n       206. , 220. , 194. ,  20. , 156. , 235. ,  24. , 223. , 178. ,\n       201. ,  22. , 173. , 190. , 135. , 137. , 134. , 118. , 148. ,\n       143. ,  93. , 144. , 127. , 149. ,  78. , 179. , 217. , 242. ,\n       250. , 218. , 241. , 228. , 182. , 144. ,  55. , 233. , 225. ,\n       235. , 243. , 238. , 221. , 190. , 185. , 205. ,  41. , 222. ,\n       226. , 177. , 169. , 239. , 104. , 147. , 135. , 124. , 134. ,\n       146. , 102. , 129. , 136. , 143. , 149. , 148. , 150. ,  87. ,\n        96. ,  37. ,  97. ,  43. ,  25. ,  99. ,  95. ,  97. ,  94. ,\n        88. ,  84. ,  33. ,  28. ,  86. , 100. ,  31. ,  30. ,  28. ,\n        27. , 149. , 147. ,  41. ,  94. , 137. , 128. , 126. , 134. ,\n       148. ,  89. , 131. ,  96. ,  97. ,  99. ,  58. ,  56. ,  62. ,\n        75. ,  72. ,  65. ,  70. ,  63. ,  73. ,  71. ,  74. ,  62. ,\n        73. ,  70. ,  65. ,  67. ,  24. ,  95. ,  90. ,  97. ,  87. ,\n       100. ,  31. ,  40. ,  52. , 118. , 142. , 137. , 146. , 132. ,\n       148. , 124. , 147. , 138. , 123. , 131. , 130. , 125.5, 150. ,\n       125.5,  28. ,  89. , 148. ,  83. , 141. , 137. , 132. , 147. ,\n        98. ,  51. ,  50. ,  97. , 100. ,  99. ,  79. ,  58. ,  92. ,\n        14. ,  75. ,  68. ,  70. ,  82. ,  94. ,  76. ,  87. ,  93. ,\n        72. ,  73. ,  75. ,  33. ,  57. ,  70. ,  74. ,  69. ,  68. ,\n       123. , 143. , 147. ,  78. , 135. ,  96. , 146. , 136. , 144. ,\n       148. , 128. , 141. , 103. , 104. , 150. , 119. ,  26. ,  92. ,\n        97. ,  94. ,  58. , 100. ,  99. ,  98. ,  29. ,  39. ,  31. ,\n        40. ,  36. ,  16. , 100. ,  97. ,  99. ,  81. ,  66. ,  92. ,\n        98. ,  79. ,  80. ,   8. ,  92. ,  99. ,  71. ,  13. ,  78. ,\n       100. ,  71. ,  94. ,  96. ,  90. ,  92. ,  80. ,  91. ,  89. ,\n        95. ,  88. ,  92. ,  79. ,  89. ,  93.5,  96. ,  93.5,  90. ,\n        76. ,  97. , 133. ,  92. ,  82. , 126. ,  98. , 136. , 141. ,\n        74. , 149. , 142. , 148. , 146. , 150. , 128. ,  63. ,  89. ,\n       123. ,  92. , 135. , 149. , 139. ,  76. , 133. ,  86. ,  73. ,\n        72. ,  58. ,  75. ,  89. ,  86. , 100. ,  76. ,  88. ,  91. ,\n        81. ,  83. ,  70. ,  99. ,  26. ,  72. ,  87.5,  93. ,  92. ,\n        67. ,  96. ,  98. ,  59. ,  87.5,  64. ,  10. , 224. , 201. ,\n       243. , 244. , 220. , 222. , 172. , 182. , 247. , 241. , 225. ,\n       157. , 238. , 207. , 185. , 193. , 214. , 192. , 171. , 219. ,\n       221. , 121. , 210. , 159. , 223. ,  98. ,  97. , 100. ,  95. ,\n        96. ,  99. ,  94. ,  77. ,  86. ,  75. ,  80. ,  92. ,  50.5,\n        66. ,  91. ,  50.5,  21. ,  20. ,  19. ,  90. ,  81. ,  65. ,\n        95. ,  90. ,  55. ,  76. ,  94. ,  72. , 100. ,  74. ,  69. ,\n        74. ,  71. ,  75. ,  72. ,  73. ,  70. ,  70. , 149. , 121. ,\n        75. , 148. , 102. ,  32. ,  24. ,  27. ,  22. , 126. , 140. ,\n       113. ,  25. ,  22. ,  74. ,  26. ,  23. ,  53. ,  70. ,  72. ,\n        75. ,  71. ,  69. ,  88. ,  46. ,  73. ,  91. ,  67. ,  65. ,\n        96. ,  92. ,  80. ,  79. ,  33. ,  69. ,  70. ,  67. ,  71. ,\n        54. ,  34. ,  31. ,  68. ,  57. ,  59. , 145. ,  82. , 135. ,\n       136. , 150. , 141. ,  64. ,  46. ,  53. ,  69. ,  54. ,  45. ,\n       149. , 138. ,  88. , 147. , 148. , 118. , 148. , 136. , 102. ,\n       103. , 144. , 104. , 126. , 150. ,  99. ,  45. ,  41. ,  92. ,\n        98. , 100. ,  94. ,  95. ,  82. ,  87. ,  91. ,  93. ,  82. ,\n        92. ,  65. ,  98. ,  97. ,  83. ,  62. ,  58. ,  99. , 100. ,\n        27. ,  34. , 178. , 221. , 226. , 246. , 233. , 242. , 182. ,\n        16. ,  37. ,  19. , 114. , 238. , 243. , 244. , 129. , 124. ,\n       143. , 134. , 225. , 186. , 218. , 232. , 192. , 120. ,  99. ,\n        97. ,  98. ,  96. ,  33. , 100. ,  92. ,  99. ,  72.5,  97. ,\n        76. ,  79. ,  47. ,  98. ,  57. , 100. ,  95. ,  72.5,  88. ,\n        91. ,  86. , 100. ,  84. ,  87. ,  58. ,  59. ,  71. ,  98. ,\n        96. ,  93. ,  66. , 129. , 128. , 122. ,  98. ,  68. , 145. ,\n       143. , 150. ,  69. , 103. , 131. , 137. ,  85. ,  54. ,  21. ,\n        34. ,  30. , 140. , 232. , 220. , 243. ,  94. ,  15. , 188. ,\n       189. , 149. , 248. , 148. , 196. , 226. , 236. , 213. , 139. ,\n       246. , 219. , 142. , 163. ,  59. ,  99. , 100. ,  51. ,  98. ,\n        60. ,  52. ,  97. ,  54. ,  96. ,  88. ,  73. ,  74. ,  26. ,\n        22. ,  23. ,  24. ,  69. ,  66. ,  69. ,  69. ,  75. ,  69. ,\n        69. ,  52. ,  99. ,  89. ,  95. ,  96. ,  85. ,  91. ,  58. ,\n        59. ,  98. ,  57. ,  72. ,  23. ,  68. ,  73. ,  53. ,  22. ,\n        75. ,  24. ,  27. ,  25. ,  73. ,  66. ,  74. ,  70.5,  72. ,\n        62. ,  70.5,  68. ,  67. ,  21. ,  48. , 149. ,  29. , 188. ,\n       153. , 219. , 246. , 177.5, 221. , 172. , 181. ,  75. , 122. ,\n       235. ,  32. , 239. , 198. , 244. , 185. ,  43. , 148. , 225. ,\n       177.5, 183. , 238. , 170. , 194. ,  94. ,  82. ,  93. ,  99. ,\n        58. ,  91. ,  97. , 100. ,  75. ,  98. ,  82. ,  27. , 100. ,\n        89. ,  94. ,  53. ,  75. ,  69. ,  65. ,  60. ,  71. ,  72. ,\n        73. ,  77. ,  64. ,  88. ,  96. ,  63. ,  95. ,  91. ,  58. ,\n        74. ,  71. , 100. ,  69. , 149. ,  92. , 143. , 118. , 141. ,\n       113. , 126. ,  90. , 147. , 148. , 122. ,  95. , 137. , 144. ,\n       150. , 123. ,  94. ,  96. ,  97. ,  44. ,  98. ,  95. ,  71. ,\n        47. ,  33. ,  26. , 186. , 196. , 225. , 246. , 244. ,  82. ,\n        31. , 118. , 226. , 184. , 238. , 221. , 233. , 248. , 173. ,\n        74. , 236. , 179. , 220. , 224. , 223. ,  88. , 245. , 178. ,\n       100. ,  59. ,  92. ,  71. ,  86.5,  96. ,  98. ,  99. ,  86.5,\n       112. , 149. ,  79. , 136. , 140. ,  68. , 138. , 150. ,  89. ,\n        29. ,  18. ,  27. , 123. ])"
     },
     "execution_count": 1824,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_pre = test.to_numpy()[data_model_test.nonzero()].flatten()\n",
    "rank_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1825,
   "outputs": [
    {
     "data": {
      "text/plain": "     index      0\n0        0   99.0\n1        1   48.0\n2        2   44.0\n3        3   36.0\n4        4   83.0\n..     ...    ...\n926    926   89.0\n927    927   29.0\n928    928   18.0\n929    929   27.0\n930    930  123.0\n\n[931 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>99.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>123.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 1825,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_pre = pd.DataFrame(rank_pre).reset_index()\n",
    "rank_pre"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1826,
   "outputs": [
    {
     "data": {
      "text/plain": "     index_1  dataset_id  model_id  balance_accuracy  prediction  rank_gt  \\\n0          0           0        72          0.940459    0.119379     17.0   \n1          1           0        78          0.999439    0.342999      5.0   \n2          2           0        79          0.999720    0.359339      2.5   \n3          3           0        81          0.999439    0.385896      5.0   \n4          4           0        83          0.560429    0.267001     29.0   \n..       ...         ...       ...               ...         ...      ...   \n926      926          71      1165          0.219891    0.179248     24.0   \n927      927          71      1451          0.168957    0.312657     95.0   \n928      928          71      1454          0.274929    0.355665     10.0   \n929      929          71      1463          0.152389    0.325650    132.0   \n930      930          71      1850          0.179178    0.137795     68.0   \n\n     index_2      0  \n0          0   99.0  \n1          1   48.0  \n2          2   44.0  \n3          3   36.0  \n4          4   83.0  \n..       ...    ...  \n926      926   89.0  \n927      927   29.0  \n928      928   18.0  \n929      929   27.0  \n930      930  123.0  \n\n[931 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index_1</th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n      <th>rank_gt</th>\n      <th>index_2</th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n      <td>17.0</td>\n      <td>0</td>\n      <td>99.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n      <td>5.0</td>\n      <td>1</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n      <td>2.5</td>\n      <td>2</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n      <td>29.0</td>\n      <td>4</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n      <td>24.0</td>\n      <td>926</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n      <td>95.0</td>\n      <td>927</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n      <td>10.0</td>\n      <td>928</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n      <td>132.0</td>\n      <td>929</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n      <td>68.0</td>\n      <td>930</td>\n      <td>123.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 1826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index()\n",
    "result = result.join(rank_pre,on='index',lsuffix='_1',rsuffix='_2')\n",
    "# result.drop('index_2')\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1827,
   "outputs": [],
   "source": [
    "result.drop('index_2', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1828,
   "outputs": [
    {
     "data": {
      "text/plain": "     index  dataset_id  model_id  balance_accuracy  prediction  rank_gt  \\\n0        0           0        72          0.940459    0.119379     17.0   \n1        1           0        78          0.999439    0.342999      5.0   \n2        2           0        79          0.999720    0.359339      2.5   \n3        3           0        81          0.999439    0.385896      5.0   \n4        4           0        83          0.560429    0.267001     29.0   \n..     ...         ...       ...               ...         ...      ...   \n926    926          71      1165          0.219891    0.179248     24.0   \n927    927          71      1451          0.168957    0.312657     95.0   \n928    928          71      1454          0.274929    0.355665     10.0   \n929    929          71      1463          0.152389    0.325650    132.0   \n930    930          71      1850          0.179178    0.137795     68.0   \n\n     rank_pre  \n0        99.0  \n1        48.0  \n2        44.0  \n3        36.0  \n4        83.0  \n..        ...  \n926      89.0  \n927      29.0  \n928      18.0  \n929      27.0  \n930     123.0  \n\n[931 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>dataset_id</th>\n      <th>model_id</th>\n      <th>balance_accuracy</th>\n      <th>prediction</th>\n      <th>rank_gt</th>\n      <th>rank_pre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0.940459</td>\n      <td>0.119379</td>\n      <td>17.0</td>\n      <td>99.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>78</td>\n      <td>0.999439</td>\n      <td>0.342999</td>\n      <td>5.0</td>\n      <td>48.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>79</td>\n      <td>0.999720</td>\n      <td>0.359339</td>\n      <td>2.5</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>81</td>\n      <td>0.999439</td>\n      <td>0.385896</td>\n      <td>5.0</td>\n      <td>36.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>83</td>\n      <td>0.560429</td>\n      <td>0.267001</td>\n      <td>29.0</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>926</th>\n      <td>926</td>\n      <td>71</td>\n      <td>1165</td>\n      <td>0.219891</td>\n      <td>0.179248</td>\n      <td>24.0</td>\n      <td>89.0</td>\n    </tr>\n    <tr>\n      <th>927</th>\n      <td>927</td>\n      <td>71</td>\n      <td>1451</td>\n      <td>0.168957</td>\n      <td>0.312657</td>\n      <td>95.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>928</td>\n      <td>71</td>\n      <td>1454</td>\n      <td>0.274929</td>\n      <td>0.355665</td>\n      <td>10.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>929</th>\n      <td>929</td>\n      <td>71</td>\n      <td>1463</td>\n      <td>0.152389</td>\n      <td>0.325650</td>\n      <td>132.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>930</td>\n      <td>71</td>\n      <td>1850</td>\n      <td>0.179178</td>\n      <td>0.137795</td>\n      <td>68.0</td>\n      <td>123.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>931 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 1828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.rename(columns={'index_1':'index', 0 : 'rank_pre'})\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1829,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 99. ,  48. ,  44. ,  36. ,  83. ,  40. ,  88. , 100. ,  98. ,\n        73. ,  89. ,  50. ,  20. , 145. , 222. , 226. ,  37. ,  40. ,\n       176. , 244. , 185. , 200. , 210. ,  81. , 217. , 121. , 199. ,\n       220. ,  94. ,  38. ,  43. ,  39. ,  98. ,  91. ,  93. , 100. ,\n        97. ,  19. ,  31. ,  83. ,  89. ,  90. ,  37. ,  41. ,  66. ,\n        40. , 143. ,  99. , 123. ,  95. , 119. , 148. ,  98. , 150. ,\n        54. , 116. ,  46. ,  19. ,  20. ,  39. , 136. , 140. , 141. ,\n       139. , 127. , 142. , 136. , 120. , 104. , 144. , 129. , 126. ,\n        93. ,  96. , 118. , 124. , 143. , 122. , 132. , 117. ,  64. ,\n       135. ,  91. ,  95. ,  94. ,  90. ,  96. ,  88. ,  99. ,   5. ,\n        93. , 100. ,  81. , 122.5, 143. , 145. , 126. , 129. , 122.5,\n       122.5,  99. , 133. ,  87. , 130. , 137. , 148. , 122.5, 147. ,\n        33. ,  35. , 246. , 220. , 221. , 230. , 243. ,  75. ,  22. ,\n       235. , 226. , 247. , 136. , 160. , 158. , 122. , 148. , 174. ,\n       214. , 175. , 168. , 187. , 222. , 152. ,  21. ,  82. ,  40. ,\n        35. ,  43. ,   4. ,   6. ,  98. ,  99. ,  77. ,  79. ,  88. ,\n        65. ,  27. ,  94. ,  20. , 244. , 179. , 250. ,  60. , 200. ,\n        12. , 220. , 221. , 204. , 164. , 132. , 223. , 188. , 208. ,\n       225. ,  11. , 232. , 217. , 224. , 219. , 184. ,  73. ,  68. ,\n        65. ,  75. ,  71. ,  27. ,  58. ,  51. ,  70. ,  59. ,  69. ,\n        74. ,  28. ,  27. , 149. , 148. , 121. , 120. , 134. , 141. ,\n       123. , 144. , 127. , 122. , 140. , 107. , 125. , 143. , 137. ,\n       150. , 124. ,  32. , 230. , 240. , 244. , 249. , 226. , 144. ,\n       206. , 220. , 194. ,  20. , 156. , 235. ,  24. , 223. , 178. ,\n       201. ,  22. , 173. , 190. , 135. , 137. , 134. , 118. , 148. ,\n       143. ,  93. , 144. , 127. , 149. ,  78. , 179. , 217. , 242. ,\n       250. , 218. , 241. , 228. , 182. , 144. ,  55. , 233. , 225. ,\n       235. , 243. , 238. , 221. , 190. , 185. , 205. ,  41. , 222. ,\n       226. , 177. , 169. , 239. , 104. , 147. , 135. , 124. , 134. ,\n       146. , 102. , 129. , 136. , 143. , 149. , 148. , 150. ,  87. ,\n        96. ,  37. ,  97. ,  43. ,  25. ,  99. ,  95. ,  97. ,  94. ,\n        88. ,  84. ,  33. ,  28. ,  86. , 100. ,  31. ,  30. ,  28. ,\n        27. , 149. , 147. ,  41. ,  94. , 137. , 128. , 126. , 134. ,\n       148. ,  89. , 131. ,  96. ,  97. ,  99. ,  58. ,  56. ,  62. ,\n        75. ,  72. ,  65. ,  70. ,  63. ,  73. ,  71. ,  74. ,  62. ,\n        73. ,  70. ,  65. ,  67. ,  24. ,  95. ,  90. ,  97. ,  87. ,\n       100. ,  31. ,  40. ,  52. , 118. , 142. , 137. , 146. , 132. ,\n       148. , 124. , 147. , 138. , 123. , 131. , 130. , 125.5, 150. ,\n       125.5,  28. ,  89. , 148. ,  83. , 141. , 137. , 132. , 147. ,\n        98. ,  51. ,  50. ,  97. , 100. ,  99. ,  79. ,  58. ,  92. ,\n        14. ,  75. ,  68. ,  70. ,  82. ,  94. ,  76. ,  87. ,  93. ,\n        72. ,  73. ,  75. ,  33. ,  57. ,  70. ,  74. ,  69. ,  68. ,\n       123. , 143. , 147. ,  78. , 135. ,  96. , 146. , 136. , 144. ,\n       148. , 128. , 141. , 103. , 104. , 150. , 119. ,  26. ,  92. ,\n        97. ,  94. ,  58. , 100. ,  99. ,  98. ,  29. ,  39. ,  31. ,\n        40. ,  36. ,  16. , 100. ,  97. ,  99. ,  81. ,  66. ,  92. ,\n        98. ,  79. ,  80. ,   8. ,  92. ,  99. ,  71. ,  13. ,  78. ,\n       100. ,  71. ,  94. ,  96. ,  90. ,  92. ,  80. ,  91. ,  89. ,\n        95. ,  88. ,  92. ,  79. ,  89. ,  93.5,  96. ,  93.5,  90. ,\n        76. ,  97. , 133. ,  92. ,  82. , 126. ,  98. , 136. , 141. ,\n        74. , 149. , 142. , 148. , 146. , 150. , 128. ,  63. ,  89. ,\n       123. ,  92. , 135. , 149. , 139. ,  76. , 133. ,  86. ,  73. ,\n        72. ,  58. ,  75. ,  89. ,  86. , 100. ,  76. ,  88. ,  91. ,\n        81. ,  83. ,  70. ,  99. ,  26. ,  72. ,  87.5,  93. ,  92. ,\n        67. ,  96. ,  98. ,  59. ,  87.5,  64. ,  10. , 224. , 201. ,\n       243. , 244. , 220. , 222. , 172. , 182. , 247. , 241. , 225. ,\n       157. , 238. , 207. , 185. , 193. , 214. , 192. , 171. , 219. ,\n       221. , 121. , 210. , 159. , 223. ,  98. ,  97. , 100. ,  95. ,\n        96. ,  99. ,  94. ,  77. ,  86. ,  75. ,  80. ,  92. ,  50.5,\n        66. ,  91. ,  50.5,  21. ,  20. ,  19. ,  90. ,  81. ,  65. ,\n        95. ,  90. ,  55. ,  76. ,  94. ,  72. , 100. ,  74. ,  69. ,\n        74. ,  71. ,  75. ,  72. ,  73. ,  70. ,  70. , 149. , 121. ,\n        75. , 148. , 102. ,  32. ,  24. ,  27. ,  22. , 126. , 140. ,\n       113. ,  25. ,  22. ,  74. ,  26. ,  23. ,  53. ,  70. ,  72. ,\n        75. ,  71. ,  69. ,  88. ,  46. ,  73. ,  91. ,  67. ,  65. ,\n        96. ,  92. ,  80. ,  79. ,  33. ,  69. ,  70. ,  67. ,  71. ,\n        54. ,  34. ,  31. ,  68. ,  57. ,  59. , 145. ,  82. , 135. ,\n       136. , 150. , 141. ,  64. ,  46. ,  53. ,  69. ,  54. ,  45. ,\n       149. , 138. ,  88. , 147. , 148. , 118. , 148. , 136. , 102. ,\n       103. , 144. , 104. , 126. , 150. ,  99. ,  45. ,  41. ,  92. ,\n        98. , 100. ,  94. ,  95. ,  82. ,  87. ,  91. ,  93. ,  82. ,\n        92. ,  65. ,  98. ,  97. ,  83. ,  62. ,  58. ,  99. , 100. ,\n        27. ,  34. , 178. , 221. , 226. , 246. , 233. , 242. , 182. ,\n        16. ,  37. ,  19. , 114. , 238. , 243. , 244. , 129. , 124. ,\n       143. , 134. , 225. , 186. , 218. , 232. , 192. , 120. ,  99. ,\n        97. ,  98. ,  96. ,  33. , 100. ,  92. ,  99. ,  72.5,  97. ,\n        76. ,  79. ,  47. ,  98. ,  57. , 100. ,  95. ,  72.5,  88. ,\n        91. ,  86. , 100. ,  84. ,  87. ,  58. ,  59. ,  71. ,  98. ,\n        96. ,  93. ,  66. , 129. , 128. , 122. ,  98. ,  68. , 145. ,\n       143. , 150. ,  69. , 103. , 131. , 137. ,  85. ,  54. ,  21. ,\n        34. ,  30. , 140. , 232. , 220. , 243. ,  94. ,  15. , 188. ,\n       189. , 149. , 248. , 148. , 196. , 226. , 236. , 213. , 139. ,\n       246. , 219. , 142. , 163. ,  59. ,  99. , 100. ,  51. ,  98. ,\n        60. ,  52. ,  97. ,  54. ,  96. ,  88. ,  73. ,  74. ,  26. ,\n        22. ,  23. ,  24. ,  69. ,  66. ,  69. ,  69. ,  75. ,  69. ,\n        69. ,  52. ,  99. ,  89. ,  95. ,  96. ,  85. ,  91. ,  58. ,\n        59. ,  98. ,  57. ,  72. ,  23. ,  68. ,  73. ,  53. ,  22. ,\n        75. ,  24. ,  27. ,  25. ,  73. ,  66. ,  74. ,  70.5,  72. ,\n        62. ,  70.5,  68. ,  67. ,  21. ,  48. , 149. ,  29. , 188. ,\n       153. , 219. , 246. , 177.5, 221. , 172. , 181. ,  75. , 122. ,\n       235. ,  32. , 239. , 198. , 244. , 185. ,  43. , 148. , 225. ,\n       177.5, 183. , 238. , 170. , 194. ,  94. ,  82. ,  93. ,  99. ,\n        58. ,  91. ,  97. , 100. ,  75. ,  98. ,  82. ,  27. , 100. ,\n        89. ,  94. ,  53. ,  75. ,  69. ,  65. ,  60. ,  71. ,  72. ,\n        73. ,  77. ,  64. ,  88. ,  96. ,  63. ,  95. ,  91. ,  58. ,\n        74. ,  71. , 100. ,  69. , 149. ,  92. , 143. , 118. , 141. ,\n       113. , 126. ,  90. , 147. , 148. , 122. ,  95. , 137. , 144. ,\n       150. , 123. ,  94. ,  96. ,  97. ,  44. ,  98. ,  95. ,  71. ,\n        47. ,  33. ,  26. , 186. , 196. , 225. , 246. , 244. ,  82. ,\n        31. , 118. , 226. , 184. , 238. , 221. , 233. , 248. , 173. ,\n        74. , 236. , 179. , 220. , 224. , 223. ,  88. , 245. , 178. ,\n       100. ,  59. ,  92. ,  71. ,  86.5,  96. ,  98. ,  99. ,  86.5,\n       112. , 149. ,  79. , 136. , 140. ,  68. , 138. , 150. ,  89. ,\n        29. ,  18. ,  27. , 123. ])"
     },
     "execution_count": 1829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['rank_pre'].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1830,
   "outputs": [
    {
     "data": {
      "text/plain": "65.29750555732274"
     },
     "execution_count": 1830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(result['rank_pre'],result['rank_gt'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1830,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}